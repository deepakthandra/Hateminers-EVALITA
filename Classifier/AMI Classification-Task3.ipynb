{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
    "import itertools\n",
    "from string import punctuation\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import pickle\n",
    "# from multilabel_data_handler import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import ensemble\n",
    "from sklearn import neural_network\n",
    "from sklearn import linear_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file used to write preserve the results of the classfier\n",
    "# confusion matrix and precision recall fscore matrix\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    \n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##saving the classification report\n",
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='macro'))\n",
    "    avg.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support','accuracy']\n",
    "    list_all=list(metrics_summary)\n",
    "    list_all.append(cm.diagonal())\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list_all,\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-2] = total\n",
    "\n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from commen_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_train_dataset = pd.read_csv('../AMI@EVALITA2018/en_training.tsv', sep='\\t')\n",
    "eng_test_dataset = pd.read_csv('../AMI@EVALITA2018/en_testing.tsv', sep='\\t')\n",
    "eng_train_dataset = eng_train_dataset.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>misogyny_category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2643</td>\n",
       "      <td>When your life's lit as FUCK https://t.co/YSSi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3177</td>\n",
       "      <td>When a baby won't stop crying so naturally you...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1827</td>\n",
       "      <td>@Oterooooo @Tigraah So you hate 'Ominous' as a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1096</td>\n",
       "      <td>I've said it before and I'll say it again. Don...</td>\n",
       "      <td>1</td>\n",
       "      <td>dominance</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3317</td>\n",
       "      <td>Instead of saying 'that's not all men' how abo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2492</td>\n",
       "      <td>An hour into 'paycheck &amp;; bills' and you reali...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2407</td>\n",
       "      <td>@kevinsd73 So true! Yet another case for #Male...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3388</td>\n",
       "      <td>@Alyssa_Milano Please take it to the streets A...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1279</td>\n",
       "      <td>I could say so much more so keep your skank of...</td>\n",
       "      <td>1</td>\n",
       "      <td>dominance</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1572</td>\n",
       "      <td>@RachaeltheLord I hate when other women drink ...</td>\n",
       "      <td>1</td>\n",
       "      <td>derailing</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1885</td>\n",
       "      <td>If you are unwilling to help victims &amp;; or sur...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3180</td>\n",
       "      <td>Me flirting- So how many filters you got on th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1440</td>\n",
       "      <td>@ohlashaybefly ctfu tell that bitch don't be s...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1428</td>\n",
       "      <td>God is dead, Jesus is a cunt and the Virgin Ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3351</td>\n",
       "      <td>Not All Men Cheat. Good morning to all the goo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>@LadyNadiaEssex Shut the fuck up ye little slag</td>\n",
       "      <td>1</td>\n",
       "      <td>dominance</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>380</td>\n",
       "      <td>Apparently 'oh you're just fat' isn't an appro...</td>\n",
       "      <td>1</td>\n",
       "      <td>derailing</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2134</td>\n",
       "      <td>MICHAEL IMMA FKN RIP YOU UP IF DONT STOP TAKIN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3475</td>\n",
       "      <td>@manwhohasitall To whom? Other hysterical men?...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>951</td>\n",
       "      <td>To the woman in a car, honking at me for two b...</td>\n",
       "      <td>1</td>\n",
       "      <td>stereotype</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1092</td>\n",
       "      <td>It figures the hurricane is named after a woma...</td>\n",
       "      <td>1</td>\n",
       "      <td>stereotype</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>545</td>\n",
       "      <td>I'm on this new diet where I only eat pussy an...</td>\n",
       "      <td>1</td>\n",
       "      <td>sexual_harassment</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>289</td>\n",
       "      <td>Women: 'started from the bottom, still here'</td>\n",
       "      <td>1</td>\n",
       "      <td>dominance</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2730</td>\n",
       "      <td>Who wore it better? https://t.co/F8xzO79fc3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2457</td>\n",
       "      <td>@bryn_adams watch the video and you'll understand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3252</td>\n",
       "      <td>Thick Slut Spreads Her Cunt And Takes A Dick h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1955</td>\n",
       "      <td>The woman who accused rapper, Nelly of rape, h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3673</td>\n",
       "      <td>i was called some type of whore or slut bc i w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3334</td>\n",
       "      <td>If you say not all men to me you're getting bl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2195</td>\n",
       "      <td>The woman who accused Nelly of rape last weeke...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>1278</td>\n",
       "      <td>I FUCKING TOLD YOU SKANK WHORE SLUTS LISTEN TO...</td>\n",
       "      <td>1</td>\n",
       "      <td>dominance</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>3052</td>\n",
       "      <td>When your selfie game is weak AF https://t.co/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>2891</td>\n",
       "      <td>Prince think he slick AF... He got everyone ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>1126</td>\n",
       "      <td>Prom is coming up boys, don't forget your comp...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>3626</td>\n",
       "      <td>New ~ https://t.co/HsEqt9GxBg Glorious ebony w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>830</td>\n",
       "      <td>What does a woman and a tampon have in common?...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>716</td>\n",
       "      <td>No one cares about you agta don't be so stupid...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>2418</td>\n",
       "      <td>RT @amyriding98: Why are guys expected to text...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>1031</td>\n",
       "      <td>@Simon_Snodgrass @BBCNewsnight @Cruella1 Yeah,...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>3030</td>\n",
       "      <td>And people with ugly faces should wear masks h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>1076</td>\n",
       "      <td>I hate When girls don't wanna start anything c...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>83</td>\n",
       "      <td>@xitsmaaarielx I miss you more main slut halav...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>1935</td>\n",
       "      <td>@is_enticing Do you take some else's help? Or ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>943</td>\n",
       "      <td>@rosemcgowan Everyone knows women are too dram...</td>\n",
       "      <td>1</td>\n",
       "      <td>stereotype</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>2187</td>\n",
       "      <td>THE RAM: Make sure you get your hands on #TheR...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>3741</td>\n",
       "      <td>@Amy_Siskind it's about time women spoke up ab...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>1064</td>\n",
       "      <td>Girls are not human beings, they're objects</td>\n",
       "      <td>1</td>\n",
       "      <td>stereotype</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>1612</td>\n",
       "      <td>pepperspray or smth, if you dont protect yours...</td>\n",
       "      <td>1</td>\n",
       "      <td>derailing</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988</th>\n",
       "      <td>952</td>\n",
       "      <td>@MsBlaireWhite Just watched the video, I thoug...</td>\n",
       "      <td>1</td>\n",
       "      <td>stereotype</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>1953</td>\n",
       "      <td>Lets go down the Slate rabbit hole: Christina ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>4022</td>\n",
       "      <td>@lloyd_frombriz @olgaNYC1211 @GOP @realDonaldT...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>3287</td>\n",
       "      <td>I hate gender -specific adjectives. Not all wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>2877</td>\n",
       "      <td>When you're having a conversation with someone...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>3212</td>\n",
       "      <td>@_celia_marie_ Whore? Really? Why don't you ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>2207</td>\n",
       "      <td>@Bill_Owen A moron thus probably thinks that r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>3328</td>\n",
       "      <td>@HYENAMISERY not all men want to give you mone...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>2800</td>\n",
       "      <td>When your friend moves away to be with someone...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>1611</td>\n",
       "      <td>stop skin out your hole and then you will see ...</td>\n",
       "      <td>1</td>\n",
       "      <td>derailing</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>3078</td>\n",
       "      <td>The real key to life is staying ahead of the game</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>1507</td>\n",
       "      <td>@RealJamesWoods @kneelandsan @Lawrence ...&gt;🔨🔨🔨...</td>\n",
       "      <td>1</td>\n",
       "      <td>stereotype</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  misogynous  \\\n",
       "0     2643  When your life's lit as FUCK https://t.co/YSSi...           0   \n",
       "1     3177  When a baby won't stop crying so naturally you...           0   \n",
       "2     1827  @Oterooooo @Tigraah So you hate 'Ominous' as a...           0   \n",
       "3     1096  I've said it before and I'll say it again. Don...           1   \n",
       "4     3317  Instead of saying 'that's not all men' how abo...           0   \n",
       "5     2492  An hour into 'paycheck &; bills' and you reali...           0   \n",
       "6     2407  @kevinsd73 So true! Yet another case for #Male...           0   \n",
       "7     3388  @Alyssa_Milano Please take it to the streets A...           0   \n",
       "8     1279  I could say so much more so keep your skank of...           1   \n",
       "9     1572  @RachaeltheLord I hate when other women drink ...           1   \n",
       "10    1885  If you are unwilling to help victims &; or sur...           0   \n",
       "11    3180  Me flirting- So how many filters you got on th...           0   \n",
       "12    1440  @ohlashaybefly ctfu tell that bitch don't be s...           1   \n",
       "13    1428  God is dead, Jesus is a cunt and the Virgin Ma...           1   \n",
       "14    3351  Not All Men Cheat. Good morning to all the goo...           0   \n",
       "15      13    @LadyNadiaEssex Shut the fuck up ye little slag           1   \n",
       "16     380  Apparently 'oh you're just fat' isn't an appro...           1   \n",
       "17    2134  MICHAEL IMMA FKN RIP YOU UP IF DONT STOP TAKIN...           0   \n",
       "18    3475  @manwhohasitall To whom? Other hysterical men?...           0   \n",
       "19     951  To the woman in a car, honking at me for two b...           1   \n",
       "20    1092  It figures the hurricane is named after a woma...           1   \n",
       "21     545  I'm on this new diet where I only eat pussy an...           1   \n",
       "22     289       Women: 'started from the bottom, still here'           1   \n",
       "23    2730        Who wore it better? https://t.co/F8xzO79fc3           0   \n",
       "24    2457  @bryn_adams watch the video and you'll understand           0   \n",
       "25    3252  Thick Slut Spreads Her Cunt And Takes A Dick h...           0   \n",
       "26    1955  The woman who accused rapper, Nelly of rape, h...           0   \n",
       "27    3673  i was called some type of whore or slut bc i w...           0   \n",
       "28    3334  If you say not all men to me you're getting bl...           0   \n",
       "29    2195  The woman who accused Nelly of rape last weeke...           0   \n",
       "...    ...                                                ...         ...   \n",
       "3970  1278  I FUCKING TOLD YOU SKANK WHORE SLUTS LISTEN TO...           1   \n",
       "3971  3052  When your selfie game is weak AF https://t.co/...           0   \n",
       "3972  2891  Prince think he slick AF... He got everyone ou...           0   \n",
       "3973  1126  Prom is coming up boys, don't forget your comp...           1   \n",
       "3974  3626  New ~ https://t.co/HsEqt9GxBg Glorious ebony w...           0   \n",
       "3975   830  What does a woman and a tampon have in common?...           1   \n",
       "3976   716  No one cares about you agta don't be so stupid...           1   \n",
       "3977  2418  RT @amyriding98: Why are guys expected to text...           0   \n",
       "3978  1031  @Simon_Snodgrass @BBCNewsnight @Cruella1 Yeah,...           1   \n",
       "3979  3030  And people with ugly faces should wear masks h...           0   \n",
       "3980  1076  I hate When girls don't wanna start anything c...           1   \n",
       "3981    83  @xitsmaaarielx I miss you more main slut halav...           1   \n",
       "3982  1935  @is_enticing Do you take some else's help? Or ...           0   \n",
       "3983   943  @rosemcgowan Everyone knows women are too dram...           1   \n",
       "3984  2187  THE RAM: Make sure you get your hands on #TheR...           0   \n",
       "3985  3741  @Amy_Siskind it's about time women spoke up ab...           0   \n",
       "3986  1064        Girls are not human beings, they're objects           1   \n",
       "3987  1612  pepperspray or smth, if you dont protect yours...           1   \n",
       "3988   952  @MsBlaireWhite Just watched the video, I thoug...           1   \n",
       "3989  1953  Lets go down the Slate rabbit hole: Christina ...           0   \n",
       "3990  4022  @lloyd_frombriz @olgaNYC1211 @GOP @realDonaldT...           1   \n",
       "3991  3287  I hate gender -specific adjectives. Not all wo...           0   \n",
       "3992  2877  When you're having a conversation with someone...           0   \n",
       "3993  3212  @_celia_marie_ Whore? Really? Why don't you ha...           0   \n",
       "3994  2207  @Bill_Owen A moron thus probably thinks that r...           0   \n",
       "3995  3328  @HYENAMISERY not all men want to give you mone...           0   \n",
       "3996  2800  When your friend moves away to be with someone...           0   \n",
       "3997  1611  stop skin out your hole and then you will see ...           1   \n",
       "3998  3078  The real key to life is staying ahead of the game           0   \n",
       "3999  1507  @RealJamesWoods @kneelandsan @Lawrence ...>🔨🔨🔨...           1   \n",
       "\n",
       "      misogyny_category   target  \n",
       "0                     0        0  \n",
       "1                     0        0  \n",
       "2                     0        0  \n",
       "3             dominance   active  \n",
       "4                     0        0  \n",
       "5                     0        0  \n",
       "6                     0        0  \n",
       "7                     0        0  \n",
       "8             dominance   active  \n",
       "9             derailing  passive  \n",
       "10                    0        0  \n",
       "11                    0        0  \n",
       "12            discredit   active  \n",
       "13            discredit   active  \n",
       "14                    0        0  \n",
       "15            dominance   active  \n",
       "16            derailing   active  \n",
       "17                    0        0  \n",
       "18                    0        0  \n",
       "19           stereotype   active  \n",
       "20           stereotype  passive  \n",
       "21    sexual_harassment  passive  \n",
       "22            dominance  passive  \n",
       "23                    0        0  \n",
       "24                    0        0  \n",
       "25                    0        0  \n",
       "26                    0        0  \n",
       "27                    0        0  \n",
       "28                    0        0  \n",
       "29                    0        0  \n",
       "...                 ...      ...  \n",
       "3970          dominance   active  \n",
       "3971                  0        0  \n",
       "3972                  0        0  \n",
       "3973          discredit  passive  \n",
       "3974                  0        0  \n",
       "3975          discredit  passive  \n",
       "3976          discredit   active  \n",
       "3977                  0        0  \n",
       "3978          discredit   active  \n",
       "3979                  0        0  \n",
       "3980          discredit  passive  \n",
       "3981          discredit   active  \n",
       "3982                  0        0  \n",
       "3983         stereotype  passive  \n",
       "3984                  0        0  \n",
       "3985                  0        0  \n",
       "3986         stereotype  passive  \n",
       "3987          derailing  passive  \n",
       "3988         stereotype   active  \n",
       "3989                  0        0  \n",
       "3990          discredit  passive  \n",
       "3991                  0        0  \n",
       "3992                  0        0  \n",
       "3993                  0        0  \n",
       "3994                  0        0  \n",
       "3995                  0        0  \n",
       "3996                  0        0  \n",
       "3997          derailing  passive  \n",
       "3998                  0        0  \n",
       "3999         stereotype   active  \n",
       "\n",
       "[4000 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2215\n",
       "active     1058\n",
       "passive     727\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_train_dataset['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Loading Glove Model\n",
      "count10000\n",
      "count20000\n",
      "count30000\n",
      "count40000\n",
      "count50000\n",
      "count60000\n",
      "count70000\n",
      "count80000\n",
      "count90000\n",
      "count100000\n",
      "count110000\n",
      "count120000\n",
      "count130000\n",
      "count140000\n",
      "count150000\n",
      "count160000\n",
      "count170000\n",
      "count180000\n",
      "count190000\n",
      "count200000\n",
      "count210000\n",
      "count220000\n",
      "count230000\n",
      "count240000\n",
      "count250000\n",
      "count260000\n",
      "count270000\n",
      "count280000\n",
      "count290000\n",
      "count300000\n",
      "count310000\n",
      "count320000\n",
      "count330000\n",
      "count340000\n",
      "count350000\n",
      "count360000\n",
      "count370000\n",
      "count380000\n",
      "count390000\n",
      "count400000\n",
      "count410000\n",
      "count420000\n",
      "count430000\n",
      "count440000\n",
      "count450000\n",
      "count460000\n",
      "count470000\n",
      "count480000\n",
      "count490000\n",
      "count500000\n",
      "count510000\n",
      "count520000\n",
      "count530000\n",
      "count540000\n",
      "count550000\n",
      "count560000\n",
      "count570000\n",
      "count580000\n",
      "count590000\n",
      "count600000\n",
      "count610000\n",
      "count620000\n",
      "count630000\n",
      "count640000\n",
      "count650000\n",
      "count660000\n",
      "count670000\n",
      "count680000\n",
      "count690000\n",
      "count700000\n",
      "count710000\n",
      "count720000\n",
      "count730000\n",
      "count740000\n",
      "count750000\n",
      "count760000\n",
      "count770000\n",
      "count780000\n",
      "count790000\n",
      "count800000\n",
      "count810000\n",
      "count820000\n",
      "count830000\n",
      "count840000\n",
      "count850000\n",
      "count860000\n",
      "count870000\n",
      "count880000\n",
      "count890000\n",
      "count900000\n",
      "count910000\n",
      "count920000\n",
      "count930000\n",
      "count940000\n",
      "count950000\n",
      "count960000\n",
      "count970000\n",
      "count980000\n",
      "count990000\n",
      "count1000000\n",
      "count1010000\n",
      "count1020000\n",
      "count1030000\n",
      "count1040000\n",
      "count1050000\n",
      "count1060000\n",
      "count1070000\n",
      "count1080000\n",
      "count1090000\n",
      "count1100000\n",
      "count1110000\n",
      "count1120000\n",
      "count1130000\n",
      "count1140000\n",
      "count1150000\n",
      "count1160000\n",
      "count1170000\n",
      "count1180000\n",
      "count1190000\n",
      "Done. 1193515  words loaded!\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "import os\n",
    "GLOVE_MODEL_FILE = \"../../LEAM-master/glove.twitter.27B/glove.twitter.27B.200d.txt\"\n",
    "# GLOVE_MODEL_FILE=\"../../../glove.840B.300d.txt\"\n",
    "print(os.path.isfile(GLOVE_MODEL_FILE))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding='utf8')\n",
    "    model = {}\n",
    "    i=0\n",
    "    for line in f:\n",
    "        i=i+1\n",
    "        splitLine = line.split(' ')\n",
    "        word = splitLine[0]\n",
    "        embedding = np.asarray(splitLine[1:], dtype='float32')\n",
    "        model[word] = embedding\n",
    "        if(i%10000==0):\n",
    "            print(\"count\"+str(i))\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "EMBEDDING_DIM = 200\n",
    "\n",
    "\n",
    "# glove_file = GLOVE_MODEL_FILE\n",
    "# tmp_file = get_tmpfile(\"test_crawl_300.txt\")\n",
    "\n",
    "# # call glove2word2vec script\n",
    "# # default way (through CLI): python -m gensim.scripts.glove2word2vec --input <glove_file> --output <w2v_file>\n",
    "# from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "# glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "\n",
    "# # In[29]:\n",
    "\n",
    "\n",
    "# word2vec_model = KeyedVectors.load_word2vec_format(tmp_file)\n",
    "word2vec_model = loadGloveModel(GLOVE_MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### stopwords and punctuations are not removed but text is cleaned and stemmed\n",
    "def glove_tokenize_norem(text):\n",
    "    #text = tokenizer(text)\n",
    "    text=clean(text, remove_stopwords=False, remove_punctuations=False)\n",
    "    words = text.split()\n",
    "    words =[ps.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "####stopwords and punctuations are removed along with that text is cleaned ans stemmed\n",
    "def glove_tokenize(text):\n",
    "    #text = tokenizer(text)\n",
    "    text=clean(text, remove_stopwords=False, remove_punctuations=False)\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in STOPWORDS]\n",
    "    words =[ps.stem(word) for word in words]\n",
    "    return words\n",
    "def glove_tokenize_embed(text):\n",
    "    #text = tokenizer(text)\n",
    "    text=clean(text, remove_stopwords=False, remove_punctuations=False)\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in STOPWORDS]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_class_label(input_text):\n",
    "    if input_text==1:\n",
    "        return 'misogyny'\n",
    "    elif input_text==0:\n",
    "        return 'non-misogyny'\n",
    "    else:\n",
    "        print('Wrong Input', input_text)\n",
    "        sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Loading Completed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binny/anaconda3/envs/punyajoy-nogpu/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# pd_train = pd.DataFrame(columns=['id','misogynous','text'])\n",
    "eng_train_dataset[\"text\"].replace('', np.nan, inplace=True)\n",
    "eng_train_dataset.dropna(subset=['text'], inplace=True)\n",
    "\n",
    "pd_train_binary = eng_train_dataset[['id','misogynous','text','misogyny_category','target']]\n",
    "pd_train_category = eng_train_dataset[['id','misogynous','text','misogyny_category']]\n",
    "pd_train_target = eng_train_dataset[['id','misogynous','text','target']]\n",
    "pd_test = eng_test_dataset[['id','text']]\n",
    "\n",
    "pd_train_category = pd_train_category.loc[pd_train_category['misogynous'] == 1]\n",
    "pd_train_target = pd_train_target.loc[pd_train_target['misogynous'] == 1]\n",
    "pd_train_target.drop(['misogynous'], axis=1)                                      \n",
    "pd_train_category.drop(['misogynous'], axis=1)                                      \n",
    "\n",
    "# pd_train['class'] =pd_train.apply(lambda row: convert_class_label(row['misogynous']), axis=1)\n",
    "\n",
    "pd_train_binary['class'] = pd_train_binary['misogynous']\n",
    "pd_train_category['class'] = pd_train_category['misogyny_category']\n",
    "pd_train_target['class'] = pd_train_target['target']\n",
    "\n",
    "# for count, each in enumerate(train_data):\n",
    "#     try:\n",
    "#         pd_train.loc[count]  = [each['id'], convert_class_label(each['CounterSpeech']), each['Community'],each['Category'],each['commentText']]\n",
    "#     except:\n",
    "#         pass\n",
    "print('Training Data Loading Completed...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(pd_train):\n",
    "    comments=pd_train['text'].values\n",
    "    labels=pd_train['class'].values\n",
    "    list_comment=[]\n",
    "    for comment,label in zip(comments,labels):\n",
    "        temp={}\n",
    "        temp['text']=comment\n",
    "        temp['label']=label\n",
    "        list_comment.append(temp)\n",
    "    return list_comment \n",
    "\n",
    "def get_data_test(pd_test):\n",
    "    comments=pd_test['text'].values\n",
    "    list_comment=[]\n",
    "    for comment in comments:\n",
    "        temp={}\n",
    "        temp['text']=comment\n",
    "        list_comment.append(temp)\n",
    "    return list_comment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binny/anaconda3/envs/punyajoy-nogpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_0:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_0\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_1:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_1\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_10:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_10\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_11:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_11\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_12:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_12\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_13:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_13\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_14:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_14\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_15:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_15\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_16:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_16\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_2:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_2\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_3:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_3\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_4:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_4\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_5:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_5\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_6:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_6\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_7:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_7\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_8:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_8\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_9:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_9\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_0/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_0/weights\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_1/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_1/weights\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_2/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_2/weights\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_3/projection:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_3/projection\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_3/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_3/weights\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/bias\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/weights\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/bias\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/weights\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/bias\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/weights\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/LinearLayer/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SNLI/Classifier/LinearLayer/bias\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/LinearLayer/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SNLI/Classifier/LinearLayer/weights\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/tanh_layer_0/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SNLI/Classifier/tanh_layer_0/bias\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/tanh_layer_0/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SNLI/Classifier/tanh_layer_0/weights\n",
      "INFO:tensorflow:Initialize variable module/global_step:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with global_step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "embed = hub.Module(module_url)\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=12,\n",
    "                       allow_soft_placement=True, device_count = {'CPU': 12})\n",
    "\n",
    "def get_embeddings(messages):\n",
    "      \n",
    "    with tf.Session(config=config) as session:\n",
    "            session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "            message_emb = session.run(embed(messages))\n",
    "            \n",
    "    print(\"ending\")\n",
    "    return np.array(message_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "TOKENIZER = glove_tokenize\n",
    "#google encoding used where text is cleaned  \n",
    "def gen_data_google(data):\n",
    "    comments = get_data(data)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        y.append(comment['label'])\n",
    "        #X.append(tokenizer(comment['text']))\n",
    "        X.append(clean(comment['text'], remove_stopwords=True, remove_punctuations=True))\n",
    "    #TFIDF_feature = 'bpe_text'\n",
    "\n",
    "    #Word Level Features\n",
    "    X =get_embeddings(X)\n",
    "    # print y\n",
    "    #y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "#google encoding used where text is not cleaned \n",
    "def gen_data_google2(data):\n",
    "    comments = get_data(data)\n",
    "    X, y = [],[]\n",
    "    for comment in comments:\n",
    "        y.append(comment['label'])\n",
    "        X.append(clean(comment['text'], remove_stopwords=False, remove_punctuations=False))\n",
    "    #Word Level Features\n",
    "    X =get_embeddings(X)\n",
    "    #y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    return X,y\n",
    "\n",
    "### tfidf feature generation was used here where stopwords and punctuations are removed \n",
    "def gen_data_new_tfidf(data):\n",
    "    comments = get_data(data)\n",
    "    comments_test=get_data_test(pd_test)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        y.append(comment['label'])\n",
    "        X.append(comment['text'])\n",
    "\n",
    "    X1=[]\n",
    "    for comment in comments_test:\n",
    "        X1.append(comment['text'])\n",
    "\n",
    "\n",
    "    #Word Level Features\n",
    "    word_vectorizer = TfidfVectorizer(sublinear_tf=True, ngram_range=(1,3),\n",
    "                min_df=1, \n",
    "                strip_accents='unicode',\n",
    "                #smooth_idf=1,\n",
    "                analyzer='word', \n",
    "                stop_words='english',\n",
    "                tokenizer=TOKENIZER,             \n",
    "                max_features=5000)\n",
    "    \n",
    "    \n",
    "    #charlevel features new\n",
    "    char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    #stop_words='english',\n",
    "    ngram_range=(2, 6),\n",
    "    max_features=10000)\n",
    "    word_vectorizer.fit(X+X1)\n",
    "    char_vectorizer.fit(X+X1)\n",
    "    \n",
    "    with open('tfidf_word_vectorizer.pk', 'wb') as fout:\n",
    "         pickle.dump(word_vectorizer,fout)\n",
    "\n",
    "    with open('tfidf_char_vectorizer.pk', 'wb') as fout:\n",
    "        pickle.dump(char_vectorizer,fout)\n",
    "    \n",
    "    test_word_features = word_vectorizer.transform(X)\n",
    "    test_char_features = char_vectorizer.transform(X)\n",
    "    X = list(hstack([test_char_features, test_word_features]).toarray())\n",
    "    #y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    return X, y\n",
    "\n",
    "### tfidf feature generation was used here where stopwords and punctuations are not removed \n",
    "def gen_data_new_tfidf2(data):\n",
    "    comments = get_data(data)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        y.append(comment['label'])\n",
    "        X.append(comment['text'])\n",
    "\n",
    "\n",
    "    #Word Level Features\n",
    "    word_vectorizer = TfidfVectorizer(sublinear_tf=True, ngram_range=(1,3),\n",
    "                min_df=1, \n",
    "                strip_accents='unicode',\n",
    "                #smooth_idf=1,\n",
    "                analyzer='word', \n",
    "                #stop_words='english',\n",
    "                tokenizer=glove_tokenize_norem,             \n",
    "                max_features=5000)\n",
    "    \n",
    "    \n",
    "    #charlevel features new\n",
    "    char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    #stop_words='english',\n",
    "    ngram_range=(2, 6),\n",
    "    max_features=10000)\n",
    "    \n",
    "    word_vectorizer.fit(X)\n",
    "    char_vectorizer.fit(X)\n",
    "    \n",
    "    with open('tfidf_word_vectorize_noclean.pk', 'wb') as fout:\n",
    "         pickle.dump(word_vectorizer,fout)\n",
    "\n",
    "    with open('tfidf_char_vectorizer_noclean.pk', 'wb') as fout:\n",
    "         pickle.dump(char_vectorizer,fout)\n",
    "        \n",
    "    test_word_features = word_vectorizer.transform(X)\n",
    "    test_char_features = char_vectorizer.transform(X)\n",
    "    X = list(hstack([test_char_features, test_word_features]).toarray())\n",
    "    #y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "## combination of not cleaned google encodings and tfidf features where stopwords and punctuations are not removed \n",
    "def combine_tf_google_rem(data):\n",
    "    X,_=gen_data_google(data)\n",
    "    X1,y=gen_data_new_tfidf(data)\n",
    "#     X1,y=gen_data_old_tfidf()\n",
    "    X=np.concatenate((np.array(X), np.array(X1)), axis=1)\n",
    "    return X,y\n",
    "\n",
    "## combination of cleaned google encodings and tfidf features where stopwords and punctuations are ssremoved \n",
    "def combine_tf_google_norem(data):\n",
    "    X,_=gen_data_google2(data)\n",
    "    X1,y=gen_data_new_tfidf2(data)\n",
    "    X=np.concatenate((np.array(X), np.array(X1)), axis=1)\n",
    "    return X,y\n",
    "\n",
    "def combine_tf_rem_google_norem(data):\n",
    "    X,_=gen_data_google2(data)\n",
    "    X1,y=gen_data_new_tfidf(data)\n",
    "    X=np.concatenate((np.array(X), np.array(X1)), axis=1)\n",
    "    return X,y\n",
    "\n",
    "def combine_tf_norem_google_rem(data):\n",
    "    X,_=gen_data_google(data)\n",
    "    X1,y=gen_data_new_tfidf2(data)\n",
    "    X=np.concatenate((np.array(X), np.array(X1)), axis=1)\n",
    "    return X,y\n",
    "\n",
    "def gen_data_embed(data):\n",
    "    comments = get_data(data)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        words = glove_tokenize(comment['text'].lower())\n",
    "        emb = np.zeros(EMBEDDING_DIM)\n",
    "        for word in words:\n",
    "            try:\n",
    "                emb += word2vec_model[word]\n",
    "            except:\n",
    "                pass\n",
    "        if len(words)!=0:\n",
    "            emb /= len(words)\n",
    "        X.append(emb)\n",
    "        y.append(comment['label'])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def combine_tf_rem_google_norem_embed(data):\n",
    "    X,_=gen_data_google2(data)\n",
    "    X1,y=gen_data_new_tfidf(data)\n",
    "    X2,_=gen_data_embed(data)\n",
    "    X=np.concatenate((np.array(X), np.array(X1),np.array(X2)), axis=1)\n",
    "    return X,y\n",
    "\n",
    "\n",
    "\n",
    "###old tfidf\n",
    "\n",
    "def gen_data_old_tfidf(data):\n",
    "    comments = get_data(data)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        y.append(comment['label'])\n",
    "        X.append(comment['text'])\n",
    "    with open('../tfidf_word_vectorizer.pk', 'rb') as fin:\n",
    "        word_vectorizer = pickle.load(fin)\n",
    "\n",
    "    with open('../tfidf_char_vectorizer.pk', 'rb') as fin:\n",
    "        char_vectorizer = pickle.load(fin)\n",
    "\n",
    "\n",
    "    \n",
    "    word_vectorizer.fit(X)\n",
    "    char_vectorizer.fit(X)\n",
    "    \n",
    "    test_word_features = word_vectorizer.transform(X)\n",
    "    test_char_features = char_vectorizer.transform(X)\n",
    "    X = list(hstack([test_char_features, test_word_features]).toarray())\n",
    "    #y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def select_comments_whose_embedding_exists(flag):\n",
    "    # selects the comments as in mean_glove_embedding method\n",
    "    # Processing\n",
    "    comments = get_data(flag)\n",
    "    X, Y = [], []\n",
    "    comment_return = []\n",
    "    for tweet in comments:\n",
    "        #print(tweet)\n",
    "        _emb = 0\n",
    "        words = TOKENIZER(tweet['text'].lower())\n",
    "        for w in words:\n",
    "            #print(w)\n",
    "            if w in word2vec_model and w is not None:  # Check if embeeding there in GLove model\n",
    "                _emb+=1\n",
    "        if _emb:   # Not a blank tweet\n",
    "            comment_return.append(tweet)\n",
    "    print('Comments selected:', len(comment_return))\n",
    "    return comment_return\n",
    "\n",
    "def gen_data():\n",
    "    comments = select_comments_whose_embedding_exists(0)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        words = glove_tokenize(comment['text'].lower())\n",
    "        emb = numpy.zeros(EMBEDDING_DIM)\n",
    "        for word in words:\n",
    "            try:\n",
    "                emb += word2vec_model[word]\n",
    "            except:\n",
    "                pass\n",
    "        emb /= len(words)\n",
    "        X.append(emb)\n",
    "        y.append(comment['label'])\n",
    "\n",
    "    # print y\n",
    "    y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    print\n",
    "    return X, y\n",
    "\n",
    "## combination of not cleaned google encodings and tfidf features where stopwords and punctuations are not removed \n",
    "def combine_tf_google_glove_rem():\n",
    "    X,_=gen_data_google()\n",
    "    X1,y=gen_data_new_tfidf()\n",
    "#     X1,y=gen_data_old_tfidf()\n",
    "    X=np.concatenate((np.array(X), np.array(X1)), axis=1)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCALE_POS_WEIGHT=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def get_model(m_type=None):\n",
    "    if not m_type:\n",
    "        print(\"ERROR: Please specify a model type!\")\n",
    "        return None\n",
    "    if m_type == 'decision_tree_classifier':\n",
    "        logreg = tree.DecisionTreeClassifier(class_weight='balanced')\n",
    "    elif m_type == 'gaussian':\n",
    "        logreg = GaussianNB()\n",
    "    elif m_type == 'logistic_regression':\n",
    "        logreg = LogisticRegression(class_weight='balanced',n_jobs=10, random_state=42)\n",
    "    elif m_type == 'MLPClassifier':\n",
    "#         logreg = neural_network.MLPClassifier((500))\n",
    "        logreg = neural_network.MLPClassifier(random_state=42,early_stopping=True)\n",
    "    elif m_type == 'KNeighborsClassifier':\n",
    "#         logreg = neighbors.KNeighborsClassifier(n_neighbors = 10)\n",
    "        logreg = neighbors.KNeighborsClassifier()\n",
    "    elif m_type == 'ExtraTreeClassifier':\n",
    "        logreg = tree.ExtraTreeClassifier()\n",
    "    elif m_type == 'ExtraTreeClassifier_2':\n",
    "        logreg = ensemble.ExtraTreesClassifier()\n",
    "    elif m_type == 'RandomForestClassifier':\n",
    "        logreg = ensemble.RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=12, max_depth=3)\n",
    "    elif m_type == 'SVC':\n",
    "        logreg = LinearSVC(class_weight='balanced');\n",
    "    elif m_type == 'Catboost':\n",
    "        logreg = CatBoostClassifier(use_best_model=False, random_state=42, scale_pos_weight=0.8)\n",
    "#         logreg = CatBoostClassifier(scale_pos_weight=0.8, random_seed=42,);\n",
    "    elif m_type == 'XGB_classifier':\n",
    "#         logreg=XGBClassifier(silent=False,eta=0.1,objective='binary:logistic',max_depth=5,min_child_weight=0,gamma=0.2,subsample=0.8, colsample_bytree = 0.8,scale_pos_weight=1,n_estimators=500,reg_lambda=3,nthread=12)\n",
    "        logreg=XGBClassifier(silent=False,objective='binary:logistic',scale_pos_weight=0.8,reg_lambda=3,nthread=12, random_state=42)\n",
    "    elif m_type == 'binny_test':\n",
    "        clf1 = ensemble.RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=12, max_depth=6,max_features='auto')\n",
    "        clf2 = tree.DecisionTreeClassifier(random_state=42, class_weight='balanced',max_depth=6)\n",
    "        clf3 = LogisticRegression(class_weight='balanced',penalty=\"l2\",C=0.1, dual=True, random_state=42, n_jobs=3)\n",
    "        clf4 = XGBClassifier(silent=False,objective='binary:logistic',scale_pos_weight=0.8,reg_lambda=3,nthread=12, random_state=42)\n",
    "        est_list = [('lr', clf1), ('rf', clf2), ('gnb', clf3), ('xgb', clf4)]\n",
    "        logreg = ensemble.VotingClassifier(est_list,voting='soft',n_jobs=6)\n",
    "    else:\n",
    "        print(\"give correct model\")\n",
    "    print(logreg)\n",
    "    return logreg\n",
    "\n",
    "def get_feature(f_type=None,data=None):\n",
    "    if not f_type:\n",
    "        print(\"ERROR: Please specify a model type!\")\n",
    "        return None\n",
    "    if f_type == 'google_not_preprocess':\n",
    "        X,y=gen_data_google2(data)\n",
    "    elif f_type == 'word_to_vec_embed':\n",
    "        X,y=gen_data_embed(data)\n",
    "    elif f_type == 'google_preprocess':\n",
    "        X,y=gen_data_google(data)\n",
    "    elif f_type == 'tfidf_not_preprocess':\n",
    "        X,y=gen_data_new_tfidf2(data)\n",
    "    elif f_type == 'tfidf_preprocess':\n",
    "        X,y=gen_data_new_tfidf(data)\n",
    "    elif f_type == 'google_preprocess_tfidf_preprocess':\n",
    "        X,y=combine_tf_google_rem(data)\n",
    "    elif f_type == 'google_nopreprocess_tfidf_nopreprocess':\n",
    "        X,y=combine_tf_google_norem(data)\n",
    "    elif f_type == 'google_preprocess_tfidf_nopreprocess':\n",
    "        X,y=combine_tf_norem_google_rem(data)\n",
    "    elif f_type == 'google_nopreprocess_tfidf_preprocess':\n",
    "        X,y=combine_tf_rem_google_norem(data)\n",
    "    elif f_type == 'google_nopreprocess_tfidf_preprocess_embed':\n",
    "        X,y=combine_tf_rem_google_norem_embed(data)\n",
    "    else:\n",
    "        print(\"give correct feature selection\")    \n",
    "    print(f_type)\n",
    "    return X,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from imblearn.combine import SMOTETomek \n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold as skf\n",
    "\n",
    "def binny_classifier_run(X,y,model,model_name,label_map,img_name,report_name,save_model=False):\n",
    "    Classifier_Train_X = np.array(X, copy=False)\n",
    "    Classifier_Train_Y = y\n",
    "    \n",
    "    \n",
    "    temp=[]\n",
    "    for data in Classifier_Train_Y:\n",
    "        temp.append(label_map[data])\n",
    "#     print(Classifier_Train_Y)\n",
    "    Classifier_Train_Y=np.array(temp)\n",
    "    model_featureSelection = SelectFromModel(ensemble.RandomForestClassifier(n_estimators=50, class_weight='balanced', \n",
    "                                                                                     n_jobs=12, max_depth=3))\n",
    "    print('Before Num features=',Classifier_Train_X.shape[1], Counter(Classifier_Train_Y))\n",
    "    Classifier_Train_X = model_featureSelection.fit_transform(Classifier_Train_X,Classifier_Train_Y)\n",
    "    print('After Num features=',Classifier_Train_X.shape[1])\n",
    "\n",
    "    if(save_model==True):\n",
    "        Classifier=model\n",
    "        Classifier.fit(Classifier_Train_X, Classifier_Train_Y)\n",
    "        filename = 'taskB2/'+model_name+'_task_3.joblib.pkl'\n",
    "        joblib.dump(Classifier, filename, compress=9)\n",
    "        filename1 = 'taskB2/'+model_name+'_select_features_task3.joblib.pkl'\n",
    "        joblib.dump(model_featureSelection, filename1, compress=9)\n",
    "    else:\n",
    "        kf = skf(n_splits=10)\n",
    "        y_total_preds=[] \n",
    "        y_total=[]\n",
    "        count=0\n",
    "\n",
    "        for train_index, test_index in kf.split(Classifier_Train_X,Classifier_Train_Y):\n",
    "    #         print('cv_fold',count)\n",
    "    #         print(train_index, test_index)\n",
    "    #         print(type(Classifier_Train_X), type(Classifier_Train_Y))\n",
    "            X_train, X_test = Classifier_Train_X[train_index], Classifier_Train_X[test_index]\n",
    "            y_train, y_test = Classifier_Train_Y[train_index], Classifier_Train_Y[test_index]\n",
    "\n",
    "        #     model_featureSelection = SelectFromModel(LogisticRegression(class_weight='balanced',penalty=\"l1\",C=0.1, dual=True, random_state=42, n_jobs=1))\n",
    "            \n",
    "        #     ada = ADASYN(random_state=42, ratio='minority')\n",
    "        #     ada = SMOTETomek(random_state=42,n_jobs=4)\n",
    "        #     X_train, y_train = ada.fit_sample(X_train, y_train)\n",
    "        #     print('After OVERSAMPLING Num poinst=', Counter(y_train))\n",
    "            classifier=model \n",
    "            classifier.fit(X_train,y_train)\n",
    "            y_preds = classifier.predict(X_test)\n",
    "            for ele in y_test:\n",
    "                y_total.append(ele)\n",
    "            for ele in y_preds:\n",
    "                y_total_preds.append(ele)\n",
    "            y_pred_train = classifier.predict(X_train)\n",
    "            count=count+1       \n",
    "            print('accuracy_train:',accuracy_score(y_train, y_pred_train),'accuracy_test:',accuracy_score(y_test, y_preds))\n",
    "            print('TRAINING:')\n",
    "            print(classification_report( y_train, y_pred_train ))\n",
    "            print(\"TESTING:\")\n",
    "            print(classification_report( y_test, y_preds ))\n",
    "\n",
    "        report = classification_report( y_total, y_total_preds )\n",
    "        cm=confusion_matrix(y_total, y_total_preds)\n",
    "        plt=plot_confusion_matrix(cm,normalize= True,target_names = ['active','passive'],title = \"Confusion Matrix\")\n",
    "        plt.savefig('task3'+model_name+'_'+img_name)\n",
    "        print(model)\n",
    "        print(report)\n",
    "        print(accuracy_score(y_total, y_total_preds))\n",
    "        df_result=pandas_classification_report(y_total,y_total_preds)\n",
    "        df_result.to_csv('task3'+model_name+'_'+report_name,  sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_model = 'gaussian'\n",
    "feature_model = 'google_nopreprocess_tfidf_preprocess_embed'\n",
    "img_name = 'cm.png'\n",
    "report_name = 'report.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending\n",
      "google_nopreprocess_tfidf_preprocess_embed\n"
     ]
    }
   ],
   "source": [
    "data_name= 'pd_train_target'\n",
    "\n",
    "if(data_name=='pd_train_binary'):\n",
    "    X,y=get_feature(f_type=feature_model,data=pd_train_binary)\n",
    "    label_map = {\n",
    "             1: 1,\n",
    "             0: 0\n",
    "                 }\n",
    "elif(data_name=='pd_train_category'):\n",
    "    X,y=get_feature(f_type=feature_model,data=pd_train_category)\n",
    "    label_map = {\n",
    "            'discredit': 0,\n",
    "            'sexual_harassment': 1,\n",
    "            'stereotype': 2,\n",
    "            'dominance': 3,\n",
    "            'derailing': 4\n",
    "        }\n",
    "elif(data_name=='pd_train_target'):\n",
    "    X,y=get_feature(f_type=feature_model,data=pd_train_target)\n",
    "    label_map = {\n",
    "             'active': 1,\n",
    "             'passive': 0\n",
    "         }\n",
    "\n",
    "else:\n",
    "    print('give correct data')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n"
     ]
    }
   ],
   "source": [
    "model=get_model(m_type=classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<catboost.core.CatBoostClassifier object at 0x7f5eb79036d8>\n",
      "Before Num features= 15712 Counter({1: 1058, 0: 727})\n",
      "After Num features= 250\n",
      "Learning rate set to 0.01974\n",
      "0:\tlearn: 0.6833435\ttotal: 93.8ms\tremaining: 1m 33s\n",
      "1:\tlearn: 0.6737663\ttotal: 130ms\tremaining: 1m 4s\n",
      "2:\tlearn: 0.6652936\ttotal: 159ms\tremaining: 52.9s\n",
      "3:\tlearn: 0.6582794\ttotal: 186ms\tremaining: 46.4s\n",
      "4:\tlearn: 0.6502234\ttotal: 212ms\tremaining: 42.1s\n",
      "5:\tlearn: 0.6433636\ttotal: 240ms\tremaining: 39.7s\n",
      "6:\tlearn: 0.6355436\ttotal: 263ms\tremaining: 37.4s\n",
      "7:\tlearn: 0.6293047\ttotal: 289ms\tremaining: 35.9s\n",
      "8:\tlearn: 0.6226024\ttotal: 317ms\tremaining: 34.9s\n",
      "9:\tlearn: 0.6152546\ttotal: 346ms\tremaining: 34.3s\n",
      "10:\tlearn: 0.6091701\ttotal: 373ms\tremaining: 33.5s\n",
      "11:\tlearn: 0.6026647\ttotal: 400ms\tremaining: 33s\n",
      "12:\tlearn: 0.5958003\ttotal: 427ms\tremaining: 32.4s\n",
      "13:\tlearn: 0.5901648\ttotal: 451ms\tremaining: 31.8s\n",
      "14:\tlearn: 0.5845848\ttotal: 477ms\tremaining: 31.3s\n",
      "15:\tlearn: 0.5784763\ttotal: 506ms\tremaining: 31.1s\n",
      "16:\tlearn: 0.5723642\ttotal: 535ms\tremaining: 30.9s\n",
      "17:\tlearn: 0.5666576\ttotal: 561ms\tremaining: 30.6s\n",
      "18:\tlearn: 0.5612778\ttotal: 590ms\tremaining: 30.5s\n",
      "19:\tlearn: 0.5560909\ttotal: 617ms\tremaining: 30.2s\n",
      "20:\tlearn: 0.5516870\ttotal: 641ms\tremaining: 29.9s\n",
      "21:\tlearn: 0.5474086\ttotal: 667ms\tremaining: 29.7s\n",
      "22:\tlearn: 0.5426254\ttotal: 694ms\tremaining: 29.5s\n",
      "23:\tlearn: 0.5378656\ttotal: 722ms\tremaining: 29.4s\n",
      "24:\tlearn: 0.5338511\ttotal: 747ms\tremaining: 29.1s\n",
      "25:\tlearn: 0.5297038\ttotal: 772ms\tremaining: 28.9s\n",
      "26:\tlearn: 0.5257774\ttotal: 797ms\tremaining: 28.7s\n",
      "27:\tlearn: 0.5214784\ttotal: 823ms\tremaining: 28.6s\n",
      "28:\tlearn: 0.5178865\ttotal: 849ms\tremaining: 28.4s\n",
      "29:\tlearn: 0.5139184\ttotal: 872ms\tremaining: 28.2s\n",
      "30:\tlearn: 0.5100340\ttotal: 897ms\tremaining: 28s\n",
      "31:\tlearn: 0.5068622\ttotal: 921ms\tremaining: 27.9s\n",
      "32:\tlearn: 0.5037137\ttotal: 945ms\tremaining: 27.7s\n",
      "33:\tlearn: 0.5000443\ttotal: 972ms\tremaining: 27.6s\n",
      "34:\tlearn: 0.4971817\ttotal: 994ms\tremaining: 27.4s\n",
      "35:\tlearn: 0.4939934\ttotal: 1.02s\tremaining: 27.3s\n",
      "36:\tlearn: 0.4911667\ttotal: 1.04s\tremaining: 27.1s\n",
      "37:\tlearn: 0.4883286\ttotal: 1.07s\tremaining: 27s\n",
      "38:\tlearn: 0.4861120\ttotal: 1.09s\tremaining: 26.9s\n",
      "39:\tlearn: 0.4833175\ttotal: 1.11s\tremaining: 26.8s\n",
      "40:\tlearn: 0.4805845\ttotal: 1.14s\tremaining: 26.6s\n",
      "41:\tlearn: 0.4780741\ttotal: 1.16s\tremaining: 26.4s\n",
      "42:\tlearn: 0.4755939\ttotal: 1.18s\tremaining: 26.3s\n",
      "43:\tlearn: 0.4731257\ttotal: 1.2s\tremaining: 26.2s\n",
      "44:\tlearn: 0.4698327\ttotal: 1.23s\tremaining: 26s\n",
      "45:\tlearn: 0.4671557\ttotal: 1.25s\tremaining: 25.9s\n",
      "46:\tlearn: 0.4649578\ttotal: 1.27s\tremaining: 25.9s\n",
      "47:\tlearn: 0.4624938\ttotal: 1.3s\tremaining: 25.8s\n",
      "48:\tlearn: 0.4598566\ttotal: 1.32s\tremaining: 25.7s\n",
      "49:\tlearn: 0.4575707\ttotal: 1.34s\tremaining: 25.5s\n",
      "50:\tlearn: 0.4554584\ttotal: 1.37s\tremaining: 25.5s\n",
      "51:\tlearn: 0.4530610\ttotal: 1.39s\tremaining: 25.4s\n",
      "52:\tlearn: 0.4509807\ttotal: 1.42s\tremaining: 25.3s\n",
      "53:\tlearn: 0.4488384\ttotal: 1.44s\tremaining: 25.2s\n",
      "54:\tlearn: 0.4468491\ttotal: 1.46s\tremaining: 25.2s\n",
      "55:\tlearn: 0.4451919\ttotal: 1.49s\tremaining: 25.1s\n",
      "56:\tlearn: 0.4436605\ttotal: 1.51s\tremaining: 25s\n",
      "57:\tlearn: 0.4419978\ttotal: 1.53s\tremaining: 24.9s\n",
      "58:\tlearn: 0.4401657\ttotal: 1.56s\tremaining: 24.8s\n",
      "59:\tlearn: 0.4383246\ttotal: 1.58s\tremaining: 24.8s\n",
      "60:\tlearn: 0.4369460\ttotal: 1.6s\tremaining: 24.7s\n",
      "61:\tlearn: 0.4353612\ttotal: 1.63s\tremaining: 24.6s\n",
      "62:\tlearn: 0.4341261\ttotal: 1.65s\tremaining: 24.6s\n",
      "63:\tlearn: 0.4319413\ttotal: 1.68s\tremaining: 24.5s\n",
      "64:\tlearn: 0.4304981\ttotal: 1.7s\tremaining: 24.4s\n",
      "65:\tlearn: 0.4288440\ttotal: 1.72s\tremaining: 24.3s\n",
      "66:\tlearn: 0.4272365\ttotal: 1.74s\tremaining: 24.3s\n",
      "67:\tlearn: 0.4252712\ttotal: 1.77s\tremaining: 24.2s\n",
      "68:\tlearn: 0.4237975\ttotal: 1.79s\tremaining: 24.2s\n",
      "69:\tlearn: 0.4221855\ttotal: 1.81s\tremaining: 24.1s\n",
      "70:\tlearn: 0.4209883\ttotal: 1.84s\tremaining: 24.1s\n",
      "71:\tlearn: 0.4195880\ttotal: 1.86s\tremaining: 24s\n",
      "72:\tlearn: 0.4181808\ttotal: 1.89s\tremaining: 24s\n",
      "73:\tlearn: 0.4163095\ttotal: 1.91s\tremaining: 23.9s\n",
      "74:\tlearn: 0.4145908\ttotal: 1.93s\tremaining: 23.9s\n",
      "75:\tlearn: 0.4130337\ttotal: 1.96s\tremaining: 23.8s\n",
      "76:\tlearn: 0.4116643\ttotal: 1.98s\tremaining: 23.8s\n",
      "77:\tlearn: 0.4100664\ttotal: 2.01s\tremaining: 23.7s\n",
      "78:\tlearn: 0.4084935\ttotal: 2.03s\tremaining: 23.7s\n",
      "79:\tlearn: 0.4071524\ttotal: 2.06s\tremaining: 23.7s\n",
      "80:\tlearn: 0.4059854\ttotal: 2.08s\tremaining: 23.6s\n",
      "81:\tlearn: 0.4046547\ttotal: 2.1s\tremaining: 23.5s\n",
      "82:\tlearn: 0.4034089\ttotal: 2.13s\tremaining: 23.5s\n",
      "83:\tlearn: 0.4022466\ttotal: 2.15s\tremaining: 23.4s\n",
      "84:\tlearn: 0.4011526\ttotal: 2.17s\tremaining: 23.4s\n",
      "85:\tlearn: 0.4002433\ttotal: 2.19s\tremaining: 23.3s\n",
      "86:\tlearn: 0.3990852\ttotal: 2.22s\tremaining: 23.3s\n",
      "87:\tlearn: 0.3977939\ttotal: 2.24s\tremaining: 23.3s\n",
      "88:\tlearn: 0.3963064\ttotal: 2.27s\tremaining: 23.2s\n",
      "89:\tlearn: 0.3950596\ttotal: 2.29s\tremaining: 23.2s\n",
      "90:\tlearn: 0.3936432\ttotal: 2.32s\tremaining: 23.2s\n",
      "91:\tlearn: 0.3925983\ttotal: 2.34s\tremaining: 23.1s\n",
      "92:\tlearn: 0.3915527\ttotal: 2.37s\tremaining: 23.1s\n",
      "93:\tlearn: 0.3904512\ttotal: 2.39s\tremaining: 23s\n",
      "94:\tlearn: 0.3893644\ttotal: 2.41s\tremaining: 23s\n",
      "95:\tlearn: 0.3880762\ttotal: 2.44s\tremaining: 23s\n",
      "96:\tlearn: 0.3870350\ttotal: 2.46s\tremaining: 22.9s\n",
      "97:\tlearn: 0.3858061\ttotal: 2.48s\tremaining: 22.9s\n",
      "98:\tlearn: 0.3843395\ttotal: 2.51s\tremaining: 22.8s\n",
      "99:\tlearn: 0.3833197\ttotal: 2.53s\tremaining: 22.8s\n",
      "100:\tlearn: 0.3824992\ttotal: 2.55s\tremaining: 22.7s\n",
      "101:\tlearn: 0.3816460\ttotal: 2.57s\tremaining: 22.7s\n",
      "102:\tlearn: 0.3805584\ttotal: 2.6s\tremaining: 22.6s\n",
      "103:\tlearn: 0.3794215\ttotal: 2.62s\tremaining: 22.6s\n",
      "104:\tlearn: 0.3784582\ttotal: 2.65s\tremaining: 22.5s\n",
      "105:\tlearn: 0.3772776\ttotal: 2.67s\tremaining: 22.5s\n",
      "106:\tlearn: 0.3763942\ttotal: 2.69s\tremaining: 22.5s\n",
      "107:\tlearn: 0.3751836\ttotal: 2.72s\tremaining: 22.4s\n",
      "108:\tlearn: 0.3743141\ttotal: 2.74s\tremaining: 22.4s\n",
      "109:\tlearn: 0.3732529\ttotal: 2.77s\tremaining: 22.4s\n",
      "110:\tlearn: 0.3722909\ttotal: 2.79s\tremaining: 22.4s\n",
      "111:\tlearn: 0.3713927\ttotal: 2.82s\tremaining: 22.3s\n",
      "112:\tlearn: 0.3705337\ttotal: 2.84s\tremaining: 22.3s\n",
      "113:\tlearn: 0.3696209\ttotal: 2.86s\tremaining: 22.2s\n",
      "114:\tlearn: 0.3689418\ttotal: 2.88s\tremaining: 22.2s\n",
      "115:\tlearn: 0.3681243\ttotal: 2.91s\tremaining: 22.1s\n",
      "116:\tlearn: 0.3668790\ttotal: 2.93s\tremaining: 22.1s\n",
      "117:\tlearn: 0.3661220\ttotal: 2.95s\tremaining: 22.1s\n",
      "118:\tlearn: 0.3652075\ttotal: 2.98s\tremaining: 22.1s\n",
      "119:\tlearn: 0.3643959\ttotal: 3s\tremaining: 22s\n",
      "120:\tlearn: 0.3635489\ttotal: 3.02s\tremaining: 22s\n",
      "121:\tlearn: 0.3628033\ttotal: 3.05s\tremaining: 21.9s\n",
      "122:\tlearn: 0.3616937\ttotal: 3.07s\tremaining: 21.9s\n",
      "123:\tlearn: 0.3611078\ttotal: 3.09s\tremaining: 21.8s\n",
      "124:\tlearn: 0.3601834\ttotal: 3.12s\tremaining: 21.8s\n",
      "125:\tlearn: 0.3594680\ttotal: 3.14s\tremaining: 21.8s\n",
      "126:\tlearn: 0.3586846\ttotal: 3.17s\tremaining: 21.8s\n",
      "127:\tlearn: 0.3577733\ttotal: 3.19s\tremaining: 21.7s\n",
      "128:\tlearn: 0.3568490\ttotal: 3.21s\tremaining: 21.7s\n",
      "129:\tlearn: 0.3559452\ttotal: 3.23s\tremaining: 21.6s\n",
      "130:\tlearn: 0.3553920\ttotal: 3.26s\tremaining: 21.6s\n",
      "131:\tlearn: 0.3545304\ttotal: 3.28s\tremaining: 21.6s\n",
      "132:\tlearn: 0.3537807\ttotal: 3.3s\tremaining: 21.5s\n",
      "133:\tlearn: 0.3531953\ttotal: 3.33s\tremaining: 21.5s\n",
      "134:\tlearn: 0.3522499\ttotal: 3.35s\tremaining: 21.5s\n",
      "135:\tlearn: 0.3516391\ttotal: 3.37s\tremaining: 21.4s\n",
      "136:\tlearn: 0.3506168\ttotal: 3.4s\tremaining: 21.4s\n",
      "137:\tlearn: 0.3498731\ttotal: 3.42s\tremaining: 21.4s\n",
      "138:\tlearn: 0.3492280\ttotal: 3.44s\tremaining: 21.3s\n",
      "139:\tlearn: 0.3484353\ttotal: 3.47s\tremaining: 21.3s\n",
      "140:\tlearn: 0.3478890\ttotal: 3.49s\tremaining: 21.3s\n",
      "141:\tlearn: 0.3472017\ttotal: 3.51s\tremaining: 21.2s\n",
      "142:\tlearn: 0.3463174\ttotal: 3.54s\tremaining: 21.2s\n",
      "143:\tlearn: 0.3453233\ttotal: 3.56s\tremaining: 21.2s\n",
      "144:\tlearn: 0.3447237\ttotal: 3.58s\tremaining: 21.1s\n",
      "145:\tlearn: 0.3438688\ttotal: 3.61s\tremaining: 21.1s\n",
      "146:\tlearn: 0.3430923\ttotal: 3.63s\tremaining: 21.1s\n",
      "147:\tlearn: 0.3424477\ttotal: 3.65s\tremaining: 21s\n",
      "148:\tlearn: 0.3419926\ttotal: 3.67s\tremaining: 21s\n",
      "149:\tlearn: 0.3413174\ttotal: 3.7s\tremaining: 21s\n",
      "150:\tlearn: 0.3404523\ttotal: 3.72s\tremaining: 20.9s\n",
      "151:\tlearn: 0.3396809\ttotal: 3.75s\tremaining: 20.9s\n",
      "152:\tlearn: 0.3390050\ttotal: 3.77s\tremaining: 20.9s\n",
      "153:\tlearn: 0.3383523\ttotal: 3.79s\tremaining: 20.8s\n",
      "154:\tlearn: 0.3377082\ttotal: 3.81s\tremaining: 20.8s\n",
      "155:\tlearn: 0.3369873\ttotal: 3.84s\tremaining: 20.8s\n",
      "156:\tlearn: 0.3361625\ttotal: 3.86s\tremaining: 20.7s\n",
      "157:\tlearn: 0.3355068\ttotal: 3.88s\tremaining: 20.7s\n",
      "158:\tlearn: 0.3350842\ttotal: 3.91s\tremaining: 20.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159:\tlearn: 0.3343662\ttotal: 3.93s\tremaining: 20.6s\n",
      "160:\tlearn: 0.3338358\ttotal: 3.95s\tremaining: 20.6s\n",
      "161:\tlearn: 0.3332355\ttotal: 3.98s\tremaining: 20.6s\n",
      "162:\tlearn: 0.3326499\ttotal: 4s\tremaining: 20.6s\n",
      "163:\tlearn: 0.3319674\ttotal: 4.03s\tremaining: 20.5s\n",
      "164:\tlearn: 0.3314248\ttotal: 4.05s\tremaining: 20.5s\n",
      "165:\tlearn: 0.3309582\ttotal: 4.07s\tremaining: 20.5s\n",
      "166:\tlearn: 0.3302581\ttotal: 4.1s\tremaining: 20.4s\n",
      "167:\tlearn: 0.3294445\ttotal: 4.12s\tremaining: 20.4s\n",
      "168:\tlearn: 0.3288913\ttotal: 4.15s\tremaining: 20.4s\n",
      "169:\tlearn: 0.3281680\ttotal: 4.17s\tremaining: 20.4s\n",
      "170:\tlearn: 0.3274449\ttotal: 4.2s\tremaining: 20.3s\n",
      "171:\tlearn: 0.3268390\ttotal: 4.22s\tremaining: 20.3s\n",
      "172:\tlearn: 0.3261830\ttotal: 4.24s\tremaining: 20.3s\n",
      "173:\tlearn: 0.3254103\ttotal: 4.26s\tremaining: 20.2s\n",
      "174:\tlearn: 0.3248113\ttotal: 4.29s\tremaining: 20.2s\n",
      "175:\tlearn: 0.3244301\ttotal: 4.31s\tremaining: 20.2s\n",
      "176:\tlearn: 0.3238577\ttotal: 4.33s\tremaining: 20.2s\n",
      "177:\tlearn: 0.3234851\ttotal: 4.35s\tremaining: 20.1s\n",
      "178:\tlearn: 0.3229189\ttotal: 4.37s\tremaining: 20.1s\n",
      "179:\tlearn: 0.3223135\ttotal: 4.4s\tremaining: 20s\n",
      "180:\tlearn: 0.3218614\ttotal: 4.42s\tremaining: 20s\n",
      "181:\tlearn: 0.3212071\ttotal: 4.44s\tremaining: 20s\n",
      "182:\tlearn: 0.3205200\ttotal: 4.47s\tremaining: 19.9s\n",
      "183:\tlearn: 0.3199881\ttotal: 4.49s\tremaining: 19.9s\n",
      "184:\tlearn: 0.3193980\ttotal: 4.51s\tremaining: 19.9s\n",
      "185:\tlearn: 0.3189357\ttotal: 4.53s\tremaining: 19.8s\n",
      "186:\tlearn: 0.3183941\ttotal: 4.56s\tremaining: 19.8s\n",
      "187:\tlearn: 0.3176568\ttotal: 4.58s\tremaining: 19.8s\n",
      "188:\tlearn: 0.3170576\ttotal: 4.6s\tremaining: 19.7s\n",
      "189:\tlearn: 0.3162150\ttotal: 4.63s\tremaining: 19.7s\n",
      "190:\tlearn: 0.3156580\ttotal: 4.65s\tremaining: 19.7s\n",
      "191:\tlearn: 0.3151568\ttotal: 4.67s\tremaining: 19.7s\n",
      "192:\tlearn: 0.3146588\ttotal: 4.69s\tremaining: 19.6s\n",
      "193:\tlearn: 0.3139995\ttotal: 4.71s\tremaining: 19.6s\n",
      "194:\tlearn: 0.3134440\ttotal: 4.74s\tremaining: 19.6s\n",
      "195:\tlearn: 0.3129956\ttotal: 4.76s\tremaining: 19.5s\n",
      "196:\tlearn: 0.3126113\ttotal: 4.78s\tremaining: 19.5s\n",
      "197:\tlearn: 0.3121343\ttotal: 4.81s\tremaining: 19.5s\n",
      "198:\tlearn: 0.3115936\ttotal: 4.83s\tremaining: 19.4s\n",
      "199:\tlearn: 0.3110233\ttotal: 4.85s\tremaining: 19.4s\n",
      "200:\tlearn: 0.3106005\ttotal: 4.87s\tremaining: 19.4s\n",
      "201:\tlearn: 0.3103410\ttotal: 4.89s\tremaining: 19.3s\n",
      "202:\tlearn: 0.3099263\ttotal: 4.92s\tremaining: 19.3s\n",
      "203:\tlearn: 0.3093816\ttotal: 4.94s\tremaining: 19.3s\n",
      "204:\tlearn: 0.3088579\ttotal: 4.97s\tremaining: 19.3s\n",
      "205:\tlearn: 0.3083839\ttotal: 4.99s\tremaining: 19.2s\n",
      "206:\tlearn: 0.3076347\ttotal: 5.01s\tremaining: 19.2s\n",
      "207:\tlearn: 0.3073241\ttotal: 5.04s\tremaining: 19.2s\n",
      "208:\tlearn: 0.3066986\ttotal: 5.06s\tremaining: 19.2s\n",
      "209:\tlearn: 0.3063911\ttotal: 5.08s\tremaining: 19.1s\n",
      "210:\tlearn: 0.3060622\ttotal: 5.11s\tremaining: 19.1s\n",
      "211:\tlearn: 0.3053199\ttotal: 5.13s\tremaining: 19.1s\n",
      "212:\tlearn: 0.3048206\ttotal: 5.15s\tremaining: 19s\n",
      "213:\tlearn: 0.3040426\ttotal: 5.17s\tremaining: 19s\n",
      "214:\tlearn: 0.3036841\ttotal: 5.2s\tremaining: 19s\n",
      "215:\tlearn: 0.3032582\ttotal: 5.22s\tremaining: 18.9s\n",
      "216:\tlearn: 0.3025129\ttotal: 5.25s\tremaining: 18.9s\n",
      "217:\tlearn: 0.3020731\ttotal: 5.26s\tremaining: 18.9s\n",
      "218:\tlearn: 0.3014053\ttotal: 5.29s\tremaining: 18.9s\n",
      "219:\tlearn: 0.3008917\ttotal: 5.31s\tremaining: 18.8s\n",
      "220:\tlearn: 0.3004794\ttotal: 5.33s\tremaining: 18.8s\n",
      "221:\tlearn: 0.2999128\ttotal: 5.35s\tremaining: 18.8s\n",
      "222:\tlearn: 0.2994145\ttotal: 5.38s\tremaining: 18.7s\n",
      "223:\tlearn: 0.2988316\ttotal: 5.41s\tremaining: 18.7s\n",
      "224:\tlearn: 0.2984184\ttotal: 5.43s\tremaining: 18.7s\n",
      "225:\tlearn: 0.2979686\ttotal: 5.45s\tremaining: 18.7s\n",
      "226:\tlearn: 0.2975282\ttotal: 5.47s\tremaining: 18.6s\n",
      "227:\tlearn: 0.2970957\ttotal: 5.5s\tremaining: 18.6s\n",
      "228:\tlearn: 0.2965385\ttotal: 5.52s\tremaining: 18.6s\n",
      "229:\tlearn: 0.2961118\ttotal: 5.54s\tremaining: 18.6s\n",
      "230:\tlearn: 0.2953240\ttotal: 5.57s\tremaining: 18.5s\n",
      "231:\tlearn: 0.2946763\ttotal: 5.59s\tremaining: 18.5s\n",
      "232:\tlearn: 0.2942627\ttotal: 5.62s\tremaining: 18.5s\n",
      "233:\tlearn: 0.2940097\ttotal: 5.63s\tremaining: 18.4s\n",
      "234:\tlearn: 0.2933801\ttotal: 5.66s\tremaining: 18.4s\n",
      "235:\tlearn: 0.2929254\ttotal: 5.68s\tremaining: 18.4s\n",
      "236:\tlearn: 0.2922065\ttotal: 5.7s\tremaining: 18.4s\n",
      "237:\tlearn: 0.2917977\ttotal: 5.72s\tremaining: 18.3s\n",
      "238:\tlearn: 0.2914780\ttotal: 5.74s\tremaining: 18.3s\n",
      "239:\tlearn: 0.2909273\ttotal: 5.76s\tremaining: 18.3s\n",
      "240:\tlearn: 0.2904642\ttotal: 5.79s\tremaining: 18.2s\n",
      "241:\tlearn: 0.2898015\ttotal: 5.81s\tremaining: 18.2s\n",
      "242:\tlearn: 0.2892345\ttotal: 5.84s\tremaining: 18.2s\n",
      "243:\tlearn: 0.2887331\ttotal: 5.86s\tremaining: 18.1s\n",
      "244:\tlearn: 0.2879831\ttotal: 5.88s\tremaining: 18.1s\n",
      "245:\tlearn: 0.2875287\ttotal: 5.9s\tremaining: 18.1s\n",
      "246:\tlearn: 0.2868278\ttotal: 5.93s\tremaining: 18.1s\n",
      "247:\tlearn: 0.2862598\ttotal: 5.95s\tremaining: 18s\n",
      "248:\tlearn: 0.2856597\ttotal: 5.97s\tremaining: 18s\n",
      "249:\tlearn: 0.2850665\ttotal: 5.99s\tremaining: 18s\n",
      "250:\tlearn: 0.2847298\ttotal: 6.02s\tremaining: 18s\n",
      "251:\tlearn: 0.2840548\ttotal: 6.04s\tremaining: 17.9s\n",
      "252:\tlearn: 0.2835636\ttotal: 6.06s\tremaining: 17.9s\n",
      "253:\tlearn: 0.2831063\ttotal: 6.08s\tremaining: 17.9s\n",
      "254:\tlearn: 0.2828528\ttotal: 6.1s\tremaining: 17.8s\n",
      "255:\tlearn: 0.2823580\ttotal: 6.13s\tremaining: 17.8s\n",
      "256:\tlearn: 0.2817260\ttotal: 6.15s\tremaining: 17.8s\n",
      "257:\tlearn: 0.2811028\ttotal: 6.18s\tremaining: 17.8s\n",
      "258:\tlearn: 0.2806832\ttotal: 6.2s\tremaining: 17.7s\n",
      "259:\tlearn: 0.2802531\ttotal: 6.22s\tremaining: 17.7s\n",
      "260:\tlearn: 0.2798851\ttotal: 6.24s\tremaining: 17.7s\n",
      "261:\tlearn: 0.2796485\ttotal: 6.26s\tremaining: 17.6s\n",
      "262:\tlearn: 0.2792164\ttotal: 6.29s\tremaining: 17.6s\n",
      "263:\tlearn: 0.2785346\ttotal: 6.31s\tremaining: 17.6s\n",
      "264:\tlearn: 0.2780167\ttotal: 6.34s\tremaining: 17.6s\n",
      "265:\tlearn: 0.2775887\ttotal: 6.36s\tremaining: 17.5s\n",
      "266:\tlearn: 0.2771483\ttotal: 6.38s\tremaining: 17.5s\n",
      "267:\tlearn: 0.2766088\ttotal: 6.4s\tremaining: 17.5s\n",
      "268:\tlearn: 0.2762184\ttotal: 6.43s\tremaining: 17.5s\n",
      "269:\tlearn: 0.2757796\ttotal: 6.45s\tremaining: 17.4s\n",
      "270:\tlearn: 0.2754839\ttotal: 6.47s\tremaining: 17.4s\n",
      "271:\tlearn: 0.2748552\ttotal: 6.49s\tremaining: 17.4s\n",
      "272:\tlearn: 0.2743675\ttotal: 6.52s\tremaining: 17.4s\n",
      "273:\tlearn: 0.2739224\ttotal: 6.54s\tremaining: 17.3s\n",
      "274:\tlearn: 0.2735239\ttotal: 6.56s\tremaining: 17.3s\n",
      "275:\tlearn: 0.2729972\ttotal: 6.58s\tremaining: 17.3s\n",
      "276:\tlearn: 0.2725647\ttotal: 6.61s\tremaining: 17.2s\n",
      "277:\tlearn: 0.2722512\ttotal: 6.63s\tremaining: 17.2s\n",
      "278:\tlearn: 0.2716833\ttotal: 6.65s\tremaining: 17.2s\n",
      "279:\tlearn: 0.2713245\ttotal: 6.67s\tremaining: 17.2s\n",
      "280:\tlearn: 0.2709131\ttotal: 6.7s\tremaining: 17.1s\n",
      "281:\tlearn: 0.2705493\ttotal: 6.72s\tremaining: 17.1s\n",
      "282:\tlearn: 0.2702874\ttotal: 6.74s\tremaining: 17.1s\n",
      "283:\tlearn: 0.2699886\ttotal: 6.76s\tremaining: 17s\n",
      "284:\tlearn: 0.2696430\ttotal: 6.78s\tremaining: 17s\n",
      "285:\tlearn: 0.2693690\ttotal: 6.8s\tremaining: 17s\n",
      "286:\tlearn: 0.2691486\ttotal: 6.82s\tremaining: 17s\n",
      "287:\tlearn: 0.2687398\ttotal: 6.84s\tremaining: 16.9s\n",
      "288:\tlearn: 0.2684621\ttotal: 6.87s\tremaining: 16.9s\n",
      "289:\tlearn: 0.2681918\ttotal: 6.89s\tremaining: 16.9s\n",
      "290:\tlearn: 0.2678198\ttotal: 6.91s\tremaining: 16.8s\n",
      "291:\tlearn: 0.2676223\ttotal: 6.93s\tremaining: 16.8s\n",
      "292:\tlearn: 0.2673881\ttotal: 6.95s\tremaining: 16.8s\n",
      "293:\tlearn: 0.2669276\ttotal: 6.97s\tremaining: 16.7s\n",
      "294:\tlearn: 0.2665141\ttotal: 7s\tremaining: 16.7s\n",
      "295:\tlearn: 0.2661206\ttotal: 7.02s\tremaining: 16.7s\n",
      "296:\tlearn: 0.2657488\ttotal: 7.04s\tremaining: 16.7s\n",
      "297:\tlearn: 0.2654654\ttotal: 7.06s\tremaining: 16.6s\n",
      "298:\tlearn: 0.2651375\ttotal: 7.08s\tremaining: 16.6s\n",
      "299:\tlearn: 0.2647586\ttotal: 7.11s\tremaining: 16.6s\n",
      "300:\tlearn: 0.2643670\ttotal: 7.13s\tremaining: 16.6s\n",
      "301:\tlearn: 0.2640362\ttotal: 7.15s\tremaining: 16.5s\n",
      "302:\tlearn: 0.2635595\ttotal: 7.17s\tremaining: 16.5s\n",
      "303:\tlearn: 0.2632365\ttotal: 7.19s\tremaining: 16.5s\n",
      "304:\tlearn: 0.2627983\ttotal: 7.21s\tremaining: 16.4s\n",
      "305:\tlearn: 0.2623389\ttotal: 7.24s\tremaining: 16.4s\n",
      "306:\tlearn: 0.2619365\ttotal: 7.26s\tremaining: 16.4s\n",
      "307:\tlearn: 0.2617964\ttotal: 7.28s\tremaining: 16.4s\n",
      "308:\tlearn: 0.2614624\ttotal: 7.3s\tremaining: 16.3s\n",
      "309:\tlearn: 0.2611452\ttotal: 7.32s\tremaining: 16.3s\n",
      "310:\tlearn: 0.2608896\ttotal: 7.34s\tremaining: 16.3s\n",
      "311:\tlearn: 0.2607081\ttotal: 7.37s\tremaining: 16.2s\n",
      "312:\tlearn: 0.2603959\ttotal: 7.39s\tremaining: 16.2s\n",
      "313:\tlearn: 0.2600033\ttotal: 7.41s\tremaining: 16.2s\n",
      "314:\tlearn: 0.2594861\ttotal: 7.43s\tremaining: 16.2s\n",
      "315:\tlearn: 0.2591133\ttotal: 7.45s\tremaining: 16.1s\n",
      "316:\tlearn: 0.2587575\ttotal: 7.48s\tremaining: 16.1s\n",
      "317:\tlearn: 0.2585244\ttotal: 7.5s\tremaining: 16.1s\n",
      "318:\tlearn: 0.2579573\ttotal: 7.52s\tremaining: 16.1s\n",
      "319:\tlearn: 0.2576731\ttotal: 7.54s\tremaining: 16s\n",
      "320:\tlearn: 0.2572514\ttotal: 7.57s\tremaining: 16s\n",
      "321:\tlearn: 0.2570354\ttotal: 7.59s\tremaining: 16s\n",
      "322:\tlearn: 0.2566267\ttotal: 7.61s\tremaining: 15.9s\n",
      "323:\tlearn: 0.2561568\ttotal: 7.63s\tremaining: 15.9s\n",
      "324:\tlearn: 0.2556174\ttotal: 7.66s\tremaining: 15.9s\n",
      "325:\tlearn: 0.2552716\ttotal: 7.68s\tremaining: 15.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326:\tlearn: 0.2547749\ttotal: 7.7s\tremaining: 15.9s\n",
      "327:\tlearn: 0.2544141\ttotal: 7.72s\tremaining: 15.8s\n",
      "328:\tlearn: 0.2539574\ttotal: 7.74s\tremaining: 15.8s\n",
      "329:\tlearn: 0.2536017\ttotal: 7.76s\tremaining: 15.8s\n",
      "330:\tlearn: 0.2531891\ttotal: 7.78s\tremaining: 15.7s\n",
      "331:\tlearn: 0.2526316\ttotal: 7.81s\tremaining: 15.7s\n",
      "332:\tlearn: 0.2521496\ttotal: 7.83s\tremaining: 15.7s\n",
      "333:\tlearn: 0.2519000\ttotal: 7.85s\tremaining: 15.7s\n",
      "334:\tlearn: 0.2515758\ttotal: 7.87s\tremaining: 15.6s\n",
      "335:\tlearn: 0.2512452\ttotal: 7.89s\tremaining: 15.6s\n",
      "336:\tlearn: 0.2509103\ttotal: 7.91s\tremaining: 15.6s\n",
      "337:\tlearn: 0.2501051\ttotal: 7.94s\tremaining: 15.5s\n",
      "338:\tlearn: 0.2497710\ttotal: 7.96s\tremaining: 15.5s\n",
      "339:\tlearn: 0.2494376\ttotal: 7.98s\tremaining: 15.5s\n",
      "340:\tlearn: 0.2491574\ttotal: 8s\tremaining: 15.5s\n",
      "341:\tlearn: 0.2488143\ttotal: 8.02s\tremaining: 15.4s\n",
      "342:\tlearn: 0.2482984\ttotal: 8.04s\tremaining: 15.4s\n",
      "343:\tlearn: 0.2480331\ttotal: 8.07s\tremaining: 15.4s\n",
      "344:\tlearn: 0.2475280\ttotal: 8.09s\tremaining: 15.4s\n",
      "345:\tlearn: 0.2469261\ttotal: 8.11s\tremaining: 15.3s\n",
      "346:\tlearn: 0.2466778\ttotal: 8.13s\tremaining: 15.3s\n",
      "347:\tlearn: 0.2464490\ttotal: 8.15s\tremaining: 15.3s\n",
      "348:\tlearn: 0.2461828\ttotal: 8.18s\tremaining: 15.3s\n",
      "349:\tlearn: 0.2456348\ttotal: 8.2s\tremaining: 15.2s\n",
      "350:\tlearn: 0.2453166\ttotal: 8.22s\tremaining: 15.2s\n",
      "351:\tlearn: 0.2448887\ttotal: 8.24s\tremaining: 15.2s\n",
      "352:\tlearn: 0.2445615\ttotal: 8.26s\tremaining: 15.1s\n",
      "353:\tlearn: 0.2442597\ttotal: 8.28s\tremaining: 15.1s\n",
      "354:\tlearn: 0.2440790\ttotal: 8.3s\tremaining: 15.1s\n",
      "355:\tlearn: 0.2436152\ttotal: 8.33s\tremaining: 15.1s\n",
      "356:\tlearn: 0.2432904\ttotal: 8.35s\tremaining: 15s\n",
      "357:\tlearn: 0.2427626\ttotal: 8.37s\tremaining: 15s\n",
      "358:\tlearn: 0.2423961\ttotal: 8.39s\tremaining: 15s\n",
      "359:\tlearn: 0.2419654\ttotal: 8.41s\tremaining: 15s\n",
      "360:\tlearn: 0.2415841\ttotal: 8.43s\tremaining: 14.9s\n",
      "361:\tlearn: 0.2411266\ttotal: 8.45s\tremaining: 14.9s\n",
      "362:\tlearn: 0.2407044\ttotal: 8.47s\tremaining: 14.9s\n",
      "363:\tlearn: 0.2404842\ttotal: 8.49s\tremaining: 14.8s\n",
      "364:\tlearn: 0.2400973\ttotal: 8.51s\tremaining: 14.8s\n",
      "365:\tlearn: 0.2398598\ttotal: 8.53s\tremaining: 14.8s\n",
      "366:\tlearn: 0.2395555\ttotal: 8.55s\tremaining: 14.8s\n",
      "367:\tlearn: 0.2392941\ttotal: 8.57s\tremaining: 14.7s\n",
      "368:\tlearn: 0.2388530\ttotal: 8.6s\tremaining: 14.7s\n",
      "369:\tlearn: 0.2385628\ttotal: 8.62s\tremaining: 14.7s\n",
      "370:\tlearn: 0.2382007\ttotal: 8.64s\tremaining: 14.6s\n",
      "371:\tlearn: 0.2379789\ttotal: 8.66s\tremaining: 14.6s\n",
      "372:\tlearn: 0.2376631\ttotal: 8.68s\tremaining: 14.6s\n",
      "373:\tlearn: 0.2373127\ttotal: 8.7s\tremaining: 14.6s\n",
      "374:\tlearn: 0.2370679\ttotal: 8.72s\tremaining: 14.5s\n",
      "375:\tlearn: 0.2367565\ttotal: 8.74s\tremaining: 14.5s\n",
      "376:\tlearn: 0.2364597\ttotal: 8.77s\tremaining: 14.5s\n",
      "377:\tlearn: 0.2361124\ttotal: 8.79s\tremaining: 14.5s\n",
      "378:\tlearn: 0.2358859\ttotal: 8.81s\tremaining: 14.4s\n",
      "379:\tlearn: 0.2356558\ttotal: 8.83s\tremaining: 14.4s\n",
      "380:\tlearn: 0.2350494\ttotal: 8.86s\tremaining: 14.4s\n",
      "381:\tlearn: 0.2347545\ttotal: 8.88s\tremaining: 14.4s\n",
      "382:\tlearn: 0.2342933\ttotal: 8.9s\tremaining: 14.3s\n",
      "383:\tlearn: 0.2338625\ttotal: 8.93s\tremaining: 14.3s\n",
      "384:\tlearn: 0.2336095\ttotal: 8.95s\tremaining: 14.3s\n",
      "385:\tlearn: 0.2332854\ttotal: 8.97s\tremaining: 14.3s\n",
      "386:\tlearn: 0.2328194\ttotal: 8.99s\tremaining: 14.2s\n",
      "387:\tlearn: 0.2326412\ttotal: 9.01s\tremaining: 14.2s\n",
      "388:\tlearn: 0.2323654\ttotal: 9.03s\tremaining: 14.2s\n",
      "389:\tlearn: 0.2321223\ttotal: 9.05s\tremaining: 14.2s\n",
      "390:\tlearn: 0.2318851\ttotal: 9.07s\tremaining: 14.1s\n",
      "391:\tlearn: 0.2314830\ttotal: 9.09s\tremaining: 14.1s\n",
      "392:\tlearn: 0.2312097\ttotal: 9.11s\tremaining: 14.1s\n",
      "393:\tlearn: 0.2306935\ttotal: 9.14s\tremaining: 14.1s\n",
      "394:\tlearn: 0.2304913\ttotal: 9.16s\tremaining: 14s\n",
      "395:\tlearn: 0.2302029\ttotal: 9.18s\tremaining: 14s\n",
      "396:\tlearn: 0.2299260\ttotal: 9.21s\tremaining: 14s\n",
      "397:\tlearn: 0.2295224\ttotal: 9.23s\tremaining: 14s\n",
      "398:\tlearn: 0.2291359\ttotal: 9.25s\tremaining: 13.9s\n",
      "399:\tlearn: 0.2289379\ttotal: 9.27s\tremaining: 13.9s\n",
      "400:\tlearn: 0.2286325\ttotal: 9.29s\tremaining: 13.9s\n",
      "401:\tlearn: 0.2281355\ttotal: 9.31s\tremaining: 13.9s\n",
      "402:\tlearn: 0.2275504\ttotal: 9.34s\tremaining: 13.8s\n",
      "403:\tlearn: 0.2273108\ttotal: 9.36s\tremaining: 13.8s\n",
      "404:\tlearn: 0.2271714\ttotal: 9.38s\tremaining: 13.8s\n",
      "405:\tlearn: 0.2268867\ttotal: 9.4s\tremaining: 13.8s\n",
      "406:\tlearn: 0.2265006\ttotal: 9.43s\tremaining: 13.7s\n",
      "407:\tlearn: 0.2261535\ttotal: 9.45s\tremaining: 13.7s\n",
      "408:\tlearn: 0.2257861\ttotal: 9.47s\tremaining: 13.7s\n",
      "409:\tlearn: 0.2252654\ttotal: 9.49s\tremaining: 13.7s\n",
      "410:\tlearn: 0.2248872\ttotal: 9.52s\tremaining: 13.6s\n",
      "411:\tlearn: 0.2244734\ttotal: 9.54s\tremaining: 13.6s\n",
      "412:\tlearn: 0.2239225\ttotal: 9.56s\tremaining: 13.6s\n",
      "413:\tlearn: 0.2234878\ttotal: 9.58s\tremaining: 13.6s\n",
      "414:\tlearn: 0.2228351\ttotal: 9.6s\tremaining: 13.5s\n",
      "415:\tlearn: 0.2226426\ttotal: 9.62s\tremaining: 13.5s\n",
      "416:\tlearn: 0.2220465\ttotal: 9.65s\tremaining: 13.5s\n",
      "417:\tlearn: 0.2217171\ttotal: 9.67s\tremaining: 13.5s\n",
      "418:\tlearn: 0.2213995\ttotal: 9.69s\tremaining: 13.4s\n",
      "419:\tlearn: 0.2211245\ttotal: 9.71s\tremaining: 13.4s\n",
      "420:\tlearn: 0.2207242\ttotal: 9.73s\tremaining: 13.4s\n",
      "421:\tlearn: 0.2202429\ttotal: 9.76s\tremaining: 13.4s\n",
      "422:\tlearn: 0.2196599\ttotal: 9.78s\tremaining: 13.3s\n",
      "423:\tlearn: 0.2194211\ttotal: 9.8s\tremaining: 13.3s\n",
      "424:\tlearn: 0.2191409\ttotal: 9.82s\tremaining: 13.3s\n",
      "425:\tlearn: 0.2187539\ttotal: 9.84s\tremaining: 13.3s\n",
      "426:\tlearn: 0.2184735\ttotal: 9.86s\tremaining: 13.2s\n",
      "427:\tlearn: 0.2181955\ttotal: 9.88s\tremaining: 13.2s\n",
      "428:\tlearn: 0.2178394\ttotal: 9.91s\tremaining: 13.2s\n",
      "429:\tlearn: 0.2175716\ttotal: 9.93s\tremaining: 13.2s\n",
      "430:\tlearn: 0.2172821\ttotal: 9.95s\tremaining: 13.1s\n",
      "431:\tlearn: 0.2169742\ttotal: 9.97s\tremaining: 13.1s\n",
      "432:\tlearn: 0.2164242\ttotal: 10s\tremaining: 13.1s\n",
      "433:\tlearn: 0.2158703\ttotal: 10s\tremaining: 13.1s\n",
      "434:\tlearn: 0.2156171\ttotal: 10s\tremaining: 13s\n",
      "435:\tlearn: 0.2153411\ttotal: 10.1s\tremaining: 13s\n",
      "436:\tlearn: 0.2151620\ttotal: 10.1s\tremaining: 13s\n",
      "437:\tlearn: 0.2148826\ttotal: 10.1s\tremaining: 13s\n",
      "438:\tlearn: 0.2145572\ttotal: 10.1s\tremaining: 12.9s\n",
      "439:\tlearn: 0.2139111\ttotal: 10.2s\tremaining: 12.9s\n",
      "440:\tlearn: 0.2135825\ttotal: 10.2s\tremaining: 12.9s\n",
      "441:\tlearn: 0.2131563\ttotal: 10.2s\tremaining: 12.9s\n",
      "442:\tlearn: 0.2128330\ttotal: 10.2s\tremaining: 12.9s\n",
      "443:\tlearn: 0.2125019\ttotal: 10.2s\tremaining: 12.8s\n",
      "444:\tlearn: 0.2123413\ttotal: 10.3s\tremaining: 12.8s\n",
      "445:\tlearn: 0.2118734\ttotal: 10.3s\tremaining: 12.8s\n",
      "446:\tlearn: 0.2116060\ttotal: 10.3s\tremaining: 12.8s\n",
      "447:\tlearn: 0.2113850\ttotal: 10.3s\tremaining: 12.7s\n",
      "448:\tlearn: 0.2111491\ttotal: 10.4s\tremaining: 12.7s\n",
      "449:\tlearn: 0.2109919\ttotal: 10.4s\tremaining: 12.7s\n",
      "450:\tlearn: 0.2107066\ttotal: 10.4s\tremaining: 12.7s\n",
      "451:\tlearn: 0.2102772\ttotal: 10.4s\tremaining: 12.6s\n",
      "452:\tlearn: 0.2098806\ttotal: 10.4s\tremaining: 12.6s\n",
      "453:\tlearn: 0.2096787\ttotal: 10.5s\tremaining: 12.6s\n",
      "454:\tlearn: 0.2093532\ttotal: 10.5s\tremaining: 12.6s\n",
      "455:\tlearn: 0.2090106\ttotal: 10.5s\tremaining: 12.5s\n",
      "456:\tlearn: 0.2087088\ttotal: 10.5s\tremaining: 12.5s\n",
      "457:\tlearn: 0.2085715\ttotal: 10.5s\tremaining: 12.5s\n",
      "458:\tlearn: 0.2081823\ttotal: 10.6s\tremaining: 12.5s\n",
      "459:\tlearn: 0.2080132\ttotal: 10.6s\tremaining: 12.4s\n",
      "460:\tlearn: 0.2077817\ttotal: 10.6s\tremaining: 12.4s\n",
      "461:\tlearn: 0.2073219\ttotal: 10.6s\tremaining: 12.4s\n",
      "462:\tlearn: 0.2069300\ttotal: 10.7s\tremaining: 12.4s\n",
      "463:\tlearn: 0.2065566\ttotal: 10.7s\tremaining: 12.3s\n",
      "464:\tlearn: 0.2062552\ttotal: 10.7s\tremaining: 12.3s\n",
      "465:\tlearn: 0.2058467\ttotal: 10.7s\tremaining: 12.3s\n",
      "466:\tlearn: 0.2054171\ttotal: 10.7s\tremaining: 12.3s\n",
      "467:\tlearn: 0.2051077\ttotal: 10.8s\tremaining: 12.2s\n",
      "468:\tlearn: 0.2048575\ttotal: 10.8s\tremaining: 12.2s\n",
      "469:\tlearn: 0.2046189\ttotal: 10.8s\tremaining: 12.2s\n",
      "470:\tlearn: 0.2043278\ttotal: 10.8s\tremaining: 12.2s\n",
      "471:\tlearn: 0.2038394\ttotal: 10.9s\tremaining: 12.1s\n",
      "472:\tlearn: 0.2034839\ttotal: 10.9s\tremaining: 12.1s\n",
      "473:\tlearn: 0.2030237\ttotal: 10.9s\tremaining: 12.1s\n",
      "474:\tlearn: 0.2025494\ttotal: 10.9s\tremaining: 12.1s\n",
      "475:\tlearn: 0.2022613\ttotal: 10.9s\tremaining: 12s\n",
      "476:\tlearn: 0.2019231\ttotal: 11s\tremaining: 12s\n",
      "477:\tlearn: 0.2016532\ttotal: 11s\tremaining: 12s\n",
      "478:\tlearn: 0.2013403\ttotal: 11s\tremaining: 12s\n",
      "479:\tlearn: 0.2011561\ttotal: 11s\tremaining: 11.9s\n",
      "480:\tlearn: 0.2008091\ttotal: 11.1s\tremaining: 11.9s\n",
      "481:\tlearn: 0.2005337\ttotal: 11.1s\tremaining: 11.9s\n",
      "482:\tlearn: 0.2002452\ttotal: 11.1s\tremaining: 11.9s\n",
      "483:\tlearn: 0.1997733\ttotal: 11.1s\tremaining: 11.9s\n",
      "484:\tlearn: 0.1996384\ttotal: 11.1s\tremaining: 11.8s\n",
      "485:\tlearn: 0.1992416\ttotal: 11.2s\tremaining: 11.8s\n",
      "486:\tlearn: 0.1989011\ttotal: 11.2s\tremaining: 11.8s\n",
      "487:\tlearn: 0.1985758\ttotal: 11.2s\tremaining: 11.8s\n",
      "488:\tlearn: 0.1982049\ttotal: 11.2s\tremaining: 11.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489:\tlearn: 0.1979359\ttotal: 11.3s\tremaining: 11.7s\n",
      "490:\tlearn: 0.1975063\ttotal: 11.3s\tremaining: 11.7s\n",
      "491:\tlearn: 0.1973262\ttotal: 11.3s\tremaining: 11.7s\n",
      "492:\tlearn: 0.1971347\ttotal: 11.3s\tremaining: 11.6s\n",
      "493:\tlearn: 0.1965910\ttotal: 11.3s\tremaining: 11.6s\n",
      "494:\tlearn: 0.1961941\ttotal: 11.4s\tremaining: 11.6s\n",
      "495:\tlearn: 0.1960025\ttotal: 11.4s\tremaining: 11.6s\n",
      "496:\tlearn: 0.1958369\ttotal: 11.4s\tremaining: 11.5s\n",
      "497:\tlearn: 0.1956215\ttotal: 11.4s\tremaining: 11.5s\n",
      "498:\tlearn: 0.1954520\ttotal: 11.5s\tremaining: 11.5s\n",
      "499:\tlearn: 0.1950662\ttotal: 11.5s\tremaining: 11.5s\n",
      "500:\tlearn: 0.1946796\ttotal: 11.5s\tremaining: 11.5s\n",
      "501:\tlearn: 0.1945630\ttotal: 11.5s\tremaining: 11.4s\n",
      "502:\tlearn: 0.1939038\ttotal: 11.5s\tremaining: 11.4s\n",
      "503:\tlearn: 0.1936067\ttotal: 11.6s\tremaining: 11.4s\n",
      "504:\tlearn: 0.1931904\ttotal: 11.6s\tremaining: 11.4s\n",
      "505:\tlearn: 0.1926666\ttotal: 11.6s\tremaining: 11.3s\n",
      "506:\tlearn: 0.1924496\ttotal: 11.6s\tremaining: 11.3s\n",
      "507:\tlearn: 0.1920788\ttotal: 11.7s\tremaining: 11.3s\n",
      "508:\tlearn: 0.1917764\ttotal: 11.7s\tremaining: 11.3s\n",
      "509:\tlearn: 0.1914551\ttotal: 11.7s\tremaining: 11.2s\n",
      "510:\tlearn: 0.1910912\ttotal: 11.7s\tremaining: 11.2s\n",
      "511:\tlearn: 0.1907249\ttotal: 11.7s\tremaining: 11.2s\n",
      "512:\tlearn: 0.1904452\ttotal: 11.8s\tremaining: 11.2s\n",
      "513:\tlearn: 0.1901309\ttotal: 11.8s\tremaining: 11.1s\n",
      "514:\tlearn: 0.1898632\ttotal: 11.8s\tremaining: 11.1s\n",
      "515:\tlearn: 0.1892819\ttotal: 11.8s\tremaining: 11.1s\n",
      "516:\tlearn: 0.1888027\ttotal: 11.9s\tremaining: 11.1s\n",
      "517:\tlearn: 0.1886120\ttotal: 11.9s\tremaining: 11.1s\n",
      "518:\tlearn: 0.1883949\ttotal: 11.9s\tremaining: 11s\n",
      "519:\tlearn: 0.1880576\ttotal: 11.9s\tremaining: 11s\n",
      "520:\tlearn: 0.1877938\ttotal: 11.9s\tremaining: 11s\n",
      "521:\tlearn: 0.1874815\ttotal: 12s\tremaining: 11s\n",
      "522:\tlearn: 0.1872983\ttotal: 12s\tremaining: 10.9s\n",
      "523:\tlearn: 0.1869968\ttotal: 12s\tremaining: 10.9s\n",
      "524:\tlearn: 0.1868406\ttotal: 12s\tremaining: 10.9s\n",
      "525:\tlearn: 0.1864345\ttotal: 12s\tremaining: 10.9s\n",
      "526:\tlearn: 0.1861038\ttotal: 12.1s\tremaining: 10.8s\n",
      "527:\tlearn: 0.1855318\ttotal: 12.1s\tremaining: 10.8s\n",
      "528:\tlearn: 0.1852928\ttotal: 12.1s\tremaining: 10.8s\n",
      "529:\tlearn: 0.1849559\ttotal: 12.1s\tremaining: 10.8s\n",
      "530:\tlearn: 0.1846513\ttotal: 12.2s\tremaining: 10.7s\n",
      "531:\tlearn: 0.1843903\ttotal: 12.2s\tremaining: 10.7s\n",
      "532:\tlearn: 0.1841394\ttotal: 12.2s\tremaining: 10.7s\n",
      "533:\tlearn: 0.1838459\ttotal: 12.2s\tremaining: 10.7s\n",
      "534:\tlearn: 0.1836105\ttotal: 12.2s\tremaining: 10.6s\n",
      "535:\tlearn: 0.1834333\ttotal: 12.3s\tremaining: 10.6s\n",
      "536:\tlearn: 0.1830397\ttotal: 12.3s\tremaining: 10.6s\n",
      "537:\tlearn: 0.1827977\ttotal: 12.3s\tremaining: 10.6s\n",
      "538:\tlearn: 0.1825567\ttotal: 12.3s\tremaining: 10.5s\n",
      "539:\tlearn: 0.1824167\ttotal: 12.4s\tremaining: 10.5s\n",
      "540:\tlearn: 0.1821614\ttotal: 12.4s\tremaining: 10.5s\n",
      "541:\tlearn: 0.1817681\ttotal: 12.4s\tremaining: 10.5s\n",
      "542:\tlearn: 0.1814401\ttotal: 12.4s\tremaining: 10.5s\n",
      "543:\tlearn: 0.1810832\ttotal: 12.4s\tremaining: 10.4s\n",
      "544:\tlearn: 0.1809309\ttotal: 12.5s\tremaining: 10.4s\n",
      "545:\tlearn: 0.1805959\ttotal: 12.5s\tremaining: 10.4s\n",
      "546:\tlearn: 0.1803627\ttotal: 12.5s\tremaining: 10.4s\n",
      "547:\tlearn: 0.1801850\ttotal: 12.5s\tremaining: 10.3s\n",
      "548:\tlearn: 0.1799286\ttotal: 12.5s\tremaining: 10.3s\n",
      "549:\tlearn: 0.1796126\ttotal: 12.6s\tremaining: 10.3s\n",
      "550:\tlearn: 0.1792572\ttotal: 12.6s\tremaining: 10.3s\n",
      "551:\tlearn: 0.1790091\ttotal: 12.6s\tremaining: 10.2s\n",
      "552:\tlearn: 0.1787959\ttotal: 12.6s\tremaining: 10.2s\n",
      "553:\tlearn: 0.1784852\ttotal: 12.7s\tremaining: 10.2s\n",
      "554:\tlearn: 0.1781544\ttotal: 12.7s\tremaining: 10.2s\n",
      "555:\tlearn: 0.1777155\ttotal: 12.7s\tremaining: 10.1s\n",
      "556:\tlearn: 0.1774003\ttotal: 12.7s\tremaining: 10.1s\n",
      "557:\tlearn: 0.1771888\ttotal: 12.8s\tremaining: 10.1s\n",
      "558:\tlearn: 0.1770290\ttotal: 12.8s\tremaining: 10.1s\n",
      "559:\tlearn: 0.1768905\ttotal: 12.8s\tremaining: 10.1s\n",
      "560:\tlearn: 0.1766974\ttotal: 12.8s\tremaining: 10s\n",
      "561:\tlearn: 0.1764973\ttotal: 12.8s\tremaining: 10s\n",
      "562:\tlearn: 0.1761382\ttotal: 12.9s\tremaining: 9.98s\n",
      "563:\tlearn: 0.1758092\ttotal: 12.9s\tremaining: 9.96s\n",
      "564:\tlearn: 0.1756362\ttotal: 12.9s\tremaining: 9.93s\n",
      "565:\tlearn: 0.1753920\ttotal: 12.9s\tremaining: 9.91s\n",
      "566:\tlearn: 0.1752047\ttotal: 12.9s\tremaining: 9.89s\n",
      "567:\tlearn: 0.1750043\ttotal: 13s\tremaining: 9.86s\n",
      "568:\tlearn: 0.1747452\ttotal: 13s\tremaining: 9.84s\n",
      "569:\tlearn: 0.1743427\ttotal: 13s\tremaining: 9.82s\n",
      "570:\tlearn: 0.1741859\ttotal: 13s\tremaining: 9.79s\n",
      "571:\tlearn: 0.1740010\ttotal: 13.1s\tremaining: 9.77s\n",
      "572:\tlearn: 0.1735210\ttotal: 13.1s\tremaining: 9.75s\n",
      "573:\tlearn: 0.1733417\ttotal: 13.1s\tremaining: 9.72s\n",
      "574:\tlearn: 0.1731396\ttotal: 13.1s\tremaining: 9.7s\n",
      "575:\tlearn: 0.1728746\ttotal: 13.1s\tremaining: 9.68s\n",
      "576:\tlearn: 0.1726709\ttotal: 13.2s\tremaining: 9.65s\n",
      "577:\tlearn: 0.1725026\ttotal: 13.2s\tremaining: 9.63s\n",
      "578:\tlearn: 0.1722396\ttotal: 13.2s\tremaining: 9.61s\n",
      "579:\tlearn: 0.1718493\ttotal: 13.2s\tremaining: 9.58s\n",
      "580:\tlearn: 0.1715575\ttotal: 13.3s\tremaining: 9.56s\n",
      "581:\tlearn: 0.1714590\ttotal: 13.3s\tremaining: 9.54s\n",
      "582:\tlearn: 0.1711013\ttotal: 13.3s\tremaining: 9.52s\n",
      "583:\tlearn: 0.1707612\ttotal: 13.3s\tremaining: 9.49s\n",
      "584:\tlearn: 0.1704436\ttotal: 13.4s\tremaining: 9.47s\n",
      "585:\tlearn: 0.1700758\ttotal: 13.4s\tremaining: 9.45s\n",
      "586:\tlearn: 0.1697820\ttotal: 13.4s\tremaining: 9.43s\n",
      "587:\tlearn: 0.1696917\ttotal: 13.4s\tremaining: 9.4s\n",
      "588:\tlearn: 0.1693461\ttotal: 13.4s\tremaining: 9.38s\n",
      "589:\tlearn: 0.1690924\ttotal: 13.5s\tremaining: 9.35s\n",
      "590:\tlearn: 0.1687858\ttotal: 13.5s\tremaining: 9.33s\n",
      "591:\tlearn: 0.1684512\ttotal: 13.5s\tremaining: 9.31s\n",
      "592:\tlearn: 0.1683056\ttotal: 13.5s\tremaining: 9.28s\n",
      "593:\tlearn: 0.1679493\ttotal: 13.6s\tremaining: 9.26s\n",
      "594:\tlearn: 0.1678473\ttotal: 13.6s\tremaining: 9.24s\n",
      "595:\tlearn: 0.1677211\ttotal: 13.6s\tremaining: 9.21s\n",
      "596:\tlearn: 0.1674394\ttotal: 13.6s\tremaining: 9.19s\n",
      "597:\tlearn: 0.1672845\ttotal: 13.6s\tremaining: 9.17s\n",
      "598:\tlearn: 0.1671063\ttotal: 13.7s\tremaining: 9.14s\n",
      "599:\tlearn: 0.1669448\ttotal: 13.7s\tremaining: 9.12s\n",
      "600:\tlearn: 0.1666055\ttotal: 13.7s\tremaining: 9.09s\n",
      "601:\tlearn: 0.1663890\ttotal: 13.7s\tremaining: 9.07s\n",
      "602:\tlearn: 0.1662339\ttotal: 13.7s\tremaining: 9.04s\n",
      "603:\tlearn: 0.1660717\ttotal: 13.8s\tremaining: 9.02s\n",
      "604:\tlearn: 0.1656693\ttotal: 13.8s\tremaining: 9s\n",
      "605:\tlearn: 0.1653943\ttotal: 13.8s\tremaining: 8.97s\n",
      "606:\tlearn: 0.1649905\ttotal: 13.8s\tremaining: 8.95s\n",
      "607:\tlearn: 0.1647430\ttotal: 13.8s\tremaining: 8.93s\n",
      "608:\tlearn: 0.1643780\ttotal: 13.9s\tremaining: 8.9s\n",
      "609:\tlearn: 0.1640222\ttotal: 13.9s\tremaining: 8.88s\n",
      "610:\tlearn: 0.1637433\ttotal: 13.9s\tremaining: 8.86s\n",
      "611:\tlearn: 0.1634663\ttotal: 13.9s\tremaining: 8.83s\n",
      "612:\tlearn: 0.1632848\ttotal: 14s\tremaining: 8.81s\n",
      "613:\tlearn: 0.1630246\ttotal: 14s\tremaining: 8.79s\n",
      "614:\tlearn: 0.1628177\ttotal: 14s\tremaining: 8.76s\n",
      "615:\tlearn: 0.1626648\ttotal: 14s\tremaining: 8.74s\n",
      "616:\tlearn: 0.1622300\ttotal: 14s\tremaining: 8.72s\n",
      "617:\tlearn: 0.1619985\ttotal: 14.1s\tremaining: 8.69s\n",
      "618:\tlearn: 0.1619122\ttotal: 14.1s\tremaining: 8.67s\n",
      "619:\tlearn: 0.1617086\ttotal: 14.1s\tremaining: 8.64s\n",
      "620:\tlearn: 0.1613178\ttotal: 14.1s\tremaining: 8.62s\n",
      "621:\tlearn: 0.1611042\ttotal: 14.1s\tremaining: 8.6s\n",
      "622:\tlearn: 0.1608426\ttotal: 14.2s\tremaining: 8.57s\n",
      "623:\tlearn: 0.1604202\ttotal: 14.2s\tremaining: 8.55s\n",
      "624:\tlearn: 0.1600474\ttotal: 14.2s\tremaining: 8.53s\n",
      "625:\tlearn: 0.1597624\ttotal: 14.2s\tremaining: 8.51s\n",
      "626:\tlearn: 0.1594424\ttotal: 14.3s\tremaining: 8.48s\n",
      "627:\tlearn: 0.1589625\ttotal: 14.3s\tremaining: 8.46s\n",
      "628:\tlearn: 0.1588583\ttotal: 14.3s\tremaining: 8.44s\n",
      "629:\tlearn: 0.1585446\ttotal: 14.3s\tremaining: 8.42s\n",
      "630:\tlearn: 0.1582828\ttotal: 14.4s\tremaining: 8.39s\n",
      "631:\tlearn: 0.1579333\ttotal: 14.4s\tremaining: 8.37s\n",
      "632:\tlearn: 0.1576554\ttotal: 14.4s\tremaining: 8.35s\n",
      "633:\tlearn: 0.1573665\ttotal: 14.4s\tremaining: 8.32s\n",
      "634:\tlearn: 0.1570773\ttotal: 14.4s\tremaining: 8.3s\n",
      "635:\tlearn: 0.1568967\ttotal: 14.5s\tremaining: 8.28s\n",
      "636:\tlearn: 0.1565444\ttotal: 14.5s\tremaining: 8.26s\n",
      "637:\tlearn: 0.1562674\ttotal: 14.5s\tremaining: 8.23s\n",
      "638:\tlearn: 0.1558988\ttotal: 14.5s\tremaining: 8.21s\n",
      "639:\tlearn: 0.1556194\ttotal: 14.6s\tremaining: 8.19s\n",
      "640:\tlearn: 0.1553982\ttotal: 14.6s\tremaining: 8.16s\n",
      "641:\tlearn: 0.1552414\ttotal: 14.6s\tremaining: 8.14s\n",
      "642:\tlearn: 0.1549445\ttotal: 14.6s\tremaining: 8.12s\n",
      "643:\tlearn: 0.1546871\ttotal: 14.7s\tremaining: 8.1s\n",
      "644:\tlearn: 0.1545021\ttotal: 14.7s\tremaining: 8.08s\n",
      "645:\tlearn: 0.1542941\ttotal: 14.7s\tremaining: 8.05s\n",
      "646:\tlearn: 0.1541036\ttotal: 14.7s\tremaining: 8.03s\n",
      "647:\tlearn: 0.1539418\ttotal: 14.7s\tremaining: 8.01s\n",
      "648:\tlearn: 0.1538139\ttotal: 14.8s\tremaining: 7.98s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649:\tlearn: 0.1535605\ttotal: 14.8s\tremaining: 7.96s\n",
      "650:\tlearn: 0.1534227\ttotal: 14.8s\tremaining: 7.94s\n",
      "651:\tlearn: 0.1532889\ttotal: 14.8s\tremaining: 7.91s\n",
      "652:\tlearn: 0.1529617\ttotal: 14.8s\tremaining: 7.89s\n",
      "653:\tlearn: 0.1527622\ttotal: 14.9s\tremaining: 7.87s\n",
      "654:\tlearn: 0.1525141\ttotal: 14.9s\tremaining: 7.84s\n",
      "655:\tlearn: 0.1523312\ttotal: 14.9s\tremaining: 7.82s\n",
      "656:\tlearn: 0.1520084\ttotal: 14.9s\tremaining: 7.8s\n",
      "657:\tlearn: 0.1518490\ttotal: 15s\tremaining: 7.77s\n",
      "658:\tlearn: 0.1515709\ttotal: 15s\tremaining: 7.75s\n",
      "659:\tlearn: 0.1512951\ttotal: 15s\tremaining: 7.73s\n",
      "660:\tlearn: 0.1510841\ttotal: 15s\tremaining: 7.71s\n",
      "661:\tlearn: 0.1509198\ttotal: 15s\tremaining: 7.68s\n",
      "662:\tlearn: 0.1506644\ttotal: 15.1s\tremaining: 7.66s\n",
      "663:\tlearn: 0.1503751\ttotal: 15.1s\tremaining: 7.63s\n",
      "664:\tlearn: 0.1502831\ttotal: 15.1s\tremaining: 7.61s\n",
      "665:\tlearn: 0.1500931\ttotal: 15.1s\tremaining: 7.59s\n",
      "666:\tlearn: 0.1500090\ttotal: 15.1s\tremaining: 7.56s\n",
      "667:\tlearn: 0.1496723\ttotal: 15.2s\tremaining: 7.54s\n",
      "668:\tlearn: 0.1494861\ttotal: 15.2s\tremaining: 7.52s\n",
      "669:\tlearn: 0.1493054\ttotal: 15.2s\tremaining: 7.49s\n",
      "670:\tlearn: 0.1489706\ttotal: 15.2s\tremaining: 7.47s\n",
      "671:\tlearn: 0.1487474\ttotal: 15.3s\tremaining: 7.45s\n",
      "672:\tlearn: 0.1486572\ttotal: 15.3s\tremaining: 7.42s\n",
      "673:\tlearn: 0.1484876\ttotal: 15.3s\tremaining: 7.4s\n",
      "674:\tlearn: 0.1483258\ttotal: 15.3s\tremaining: 7.38s\n",
      "675:\tlearn: 0.1481332\ttotal: 15.3s\tremaining: 7.35s\n",
      "676:\tlearn: 0.1478475\ttotal: 15.4s\tremaining: 7.33s\n",
      "677:\tlearn: 0.1476398\ttotal: 15.4s\tremaining: 7.31s\n",
      "678:\tlearn: 0.1473937\ttotal: 15.4s\tremaining: 7.28s\n",
      "679:\tlearn: 0.1472360\ttotal: 15.4s\tremaining: 7.26s\n",
      "680:\tlearn: 0.1470727\ttotal: 15.4s\tremaining: 7.24s\n",
      "681:\tlearn: 0.1468580\ttotal: 15.5s\tremaining: 7.21s\n",
      "682:\tlearn: 0.1467965\ttotal: 15.5s\tremaining: 7.19s\n",
      "683:\tlearn: 0.1465591\ttotal: 15.5s\tremaining: 7.17s\n",
      "684:\tlearn: 0.1463084\ttotal: 15.5s\tremaining: 7.14s\n",
      "685:\tlearn: 0.1462147\ttotal: 15.6s\tremaining: 7.12s\n",
      "686:\tlearn: 0.1460630\ttotal: 15.6s\tremaining: 7.1s\n",
      "687:\tlearn: 0.1458930\ttotal: 15.6s\tremaining: 7.07s\n",
      "688:\tlearn: 0.1455907\ttotal: 15.6s\tremaining: 7.05s\n",
      "689:\tlearn: 0.1453458\ttotal: 15.6s\tremaining: 7.03s\n",
      "690:\tlearn: 0.1450596\ttotal: 15.7s\tremaining: 7.01s\n",
      "691:\tlearn: 0.1447559\ttotal: 15.7s\tremaining: 6.99s\n",
      "692:\tlearn: 0.1446136\ttotal: 15.7s\tremaining: 6.96s\n",
      "693:\tlearn: 0.1444951\ttotal: 15.7s\tremaining: 6.94s\n",
      "694:\tlearn: 0.1442857\ttotal: 15.8s\tremaining: 6.91s\n",
      "695:\tlearn: 0.1439370\ttotal: 15.8s\tremaining: 6.89s\n",
      "696:\tlearn: 0.1438107\ttotal: 15.8s\tremaining: 6.87s\n",
      "697:\tlearn: 0.1435905\ttotal: 15.8s\tremaining: 6.84s\n",
      "698:\tlearn: 0.1433979\ttotal: 15.8s\tremaining: 6.82s\n",
      "699:\tlearn: 0.1432000\ttotal: 15.9s\tremaining: 6.8s\n",
      "700:\tlearn: 0.1431153\ttotal: 15.9s\tremaining: 6.78s\n",
      "701:\tlearn: 0.1429978\ttotal: 15.9s\tremaining: 6.75s\n",
      "702:\tlearn: 0.1427700\ttotal: 15.9s\tremaining: 6.73s\n",
      "703:\tlearn: 0.1425292\ttotal: 16s\tremaining: 6.71s\n",
      "704:\tlearn: 0.1422434\ttotal: 16s\tremaining: 6.68s\n",
      "705:\tlearn: 0.1420896\ttotal: 16s\tremaining: 6.66s\n",
      "706:\tlearn: 0.1419381\ttotal: 16s\tremaining: 6.64s\n",
      "707:\tlearn: 0.1417612\ttotal: 16s\tremaining: 6.61s\n",
      "708:\tlearn: 0.1415487\ttotal: 16.1s\tremaining: 6.59s\n",
      "709:\tlearn: 0.1413888\ttotal: 16.1s\tremaining: 6.57s\n",
      "710:\tlearn: 0.1412404\ttotal: 16.1s\tremaining: 6.54s\n",
      "711:\tlearn: 0.1409246\ttotal: 16.1s\tremaining: 6.52s\n",
      "712:\tlearn: 0.1407949\ttotal: 16.1s\tremaining: 6.5s\n",
      "713:\tlearn: 0.1406962\ttotal: 16.2s\tremaining: 6.47s\n",
      "714:\tlearn: 0.1404249\ttotal: 16.2s\tremaining: 6.45s\n",
      "715:\tlearn: 0.1402390\ttotal: 16.2s\tremaining: 6.43s\n",
      "716:\tlearn: 0.1400200\ttotal: 16.2s\tremaining: 6.41s\n",
      "717:\tlearn: 0.1397219\ttotal: 16.3s\tremaining: 6.38s\n",
      "718:\tlearn: 0.1396163\ttotal: 16.3s\tremaining: 6.36s\n",
      "719:\tlearn: 0.1395083\ttotal: 16.3s\tremaining: 6.34s\n",
      "720:\tlearn: 0.1394389\ttotal: 16.3s\tremaining: 6.31s\n",
      "721:\tlearn: 0.1392290\ttotal: 16.3s\tremaining: 6.29s\n",
      "722:\tlearn: 0.1389860\ttotal: 16.4s\tremaining: 6.27s\n",
      "723:\tlearn: 0.1387174\ttotal: 16.4s\tremaining: 6.25s\n",
      "724:\tlearn: 0.1383832\ttotal: 16.4s\tremaining: 6.22s\n",
      "725:\tlearn: 0.1381316\ttotal: 16.4s\tremaining: 6.2s\n",
      "726:\tlearn: 0.1379906\ttotal: 16.4s\tremaining: 6.18s\n",
      "727:\tlearn: 0.1377686\ttotal: 16.5s\tremaining: 6.16s\n",
      "728:\tlearn: 0.1374693\ttotal: 16.5s\tremaining: 6.13s\n",
      "729:\tlearn: 0.1371831\ttotal: 16.5s\tremaining: 6.11s\n",
      "730:\tlearn: 0.1369251\ttotal: 16.5s\tremaining: 6.09s\n",
      "731:\tlearn: 0.1368405\ttotal: 16.6s\tremaining: 6.06s\n",
      "732:\tlearn: 0.1365218\ttotal: 16.6s\tremaining: 6.04s\n",
      "733:\tlearn: 0.1362631\ttotal: 16.6s\tremaining: 6.02s\n",
      "734:\tlearn: 0.1360640\ttotal: 16.6s\tremaining: 6s\n",
      "735:\tlearn: 0.1359529\ttotal: 16.6s\tremaining: 5.97s\n",
      "736:\tlearn: 0.1357683\ttotal: 16.7s\tremaining: 5.95s\n",
      "737:\tlearn: 0.1356221\ttotal: 16.7s\tremaining: 5.92s\n",
      "738:\tlearn: 0.1355187\ttotal: 16.7s\tremaining: 5.9s\n",
      "739:\tlearn: 0.1353463\ttotal: 16.7s\tremaining: 5.88s\n",
      "740:\tlearn: 0.1352350\ttotal: 16.7s\tremaining: 5.85s\n",
      "741:\tlearn: 0.1350218\ttotal: 16.8s\tremaining: 5.83s\n",
      "742:\tlearn: 0.1348368\ttotal: 16.8s\tremaining: 5.81s\n",
      "743:\tlearn: 0.1345931\ttotal: 16.8s\tremaining: 5.79s\n",
      "744:\tlearn: 0.1344420\ttotal: 16.8s\tremaining: 5.76s\n",
      "745:\tlearn: 0.1343747\ttotal: 16.9s\tremaining: 5.74s\n",
      "746:\tlearn: 0.1341518\ttotal: 16.9s\tremaining: 5.71s\n",
      "747:\tlearn: 0.1338865\ttotal: 16.9s\tremaining: 5.69s\n",
      "748:\tlearn: 0.1335064\ttotal: 16.9s\tremaining: 5.67s\n",
      "749:\tlearn: 0.1333329\ttotal: 17s\tremaining: 5.65s\n",
      "750:\tlearn: 0.1331496\ttotal: 17s\tremaining: 5.63s\n",
      "751:\tlearn: 0.1329766\ttotal: 17s\tremaining: 5.6s\n",
      "752:\tlearn: 0.1329033\ttotal: 17s\tremaining: 5.58s\n",
      "753:\tlearn: 0.1326589\ttotal: 17s\tremaining: 5.56s\n",
      "754:\tlearn: 0.1325065\ttotal: 17.1s\tremaining: 5.53s\n",
      "755:\tlearn: 0.1323900\ttotal: 17.1s\tremaining: 5.51s\n",
      "756:\tlearn: 0.1320624\ttotal: 17.1s\tremaining: 5.49s\n",
      "757:\tlearn: 0.1318894\ttotal: 17.1s\tremaining: 5.46s\n",
      "758:\tlearn: 0.1315157\ttotal: 17.1s\tremaining: 5.44s\n",
      "759:\tlearn: 0.1312194\ttotal: 17.2s\tremaining: 5.42s\n",
      "760:\tlearn: 0.1310048\ttotal: 17.2s\tremaining: 5.4s\n",
      "761:\tlearn: 0.1308373\ttotal: 17.2s\tremaining: 5.37s\n",
      "762:\tlearn: 0.1307063\ttotal: 17.2s\tremaining: 5.35s\n",
      "763:\tlearn: 0.1304744\ttotal: 17.3s\tremaining: 5.33s\n",
      "764:\tlearn: 0.1303317\ttotal: 17.3s\tremaining: 5.3s\n",
      "765:\tlearn: 0.1300806\ttotal: 17.3s\tremaining: 5.28s\n",
      "766:\tlearn: 0.1298441\ttotal: 17.3s\tremaining: 5.26s\n",
      "767:\tlearn: 0.1296743\ttotal: 17.3s\tremaining: 5.24s\n",
      "768:\tlearn: 0.1296270\ttotal: 17.4s\tremaining: 5.21s\n",
      "769:\tlearn: 0.1293492\ttotal: 17.4s\tremaining: 5.19s\n",
      "770:\tlearn: 0.1292580\ttotal: 17.4s\tremaining: 5.17s\n",
      "771:\tlearn: 0.1288975\ttotal: 17.4s\tremaining: 5.15s\n",
      "772:\tlearn: 0.1286987\ttotal: 17.5s\tremaining: 5.12s\n",
      "773:\tlearn: 0.1285063\ttotal: 17.5s\tremaining: 5.1s\n",
      "774:\tlearn: 0.1282790\ttotal: 17.5s\tremaining: 5.08s\n",
      "775:\tlearn: 0.1281500\ttotal: 17.5s\tremaining: 5.06s\n",
      "776:\tlearn: 0.1280188\ttotal: 17.5s\tremaining: 5.03s\n",
      "777:\tlearn: 0.1278095\ttotal: 17.6s\tremaining: 5.01s\n",
      "778:\tlearn: 0.1275437\ttotal: 17.6s\tremaining: 4.99s\n",
      "779:\tlearn: 0.1273022\ttotal: 17.6s\tremaining: 4.97s\n",
      "780:\tlearn: 0.1271572\ttotal: 17.6s\tremaining: 4.94s\n",
      "781:\tlearn: 0.1270789\ttotal: 17.7s\tremaining: 4.92s\n",
      "782:\tlearn: 0.1267196\ttotal: 17.7s\tremaining: 4.9s\n",
      "783:\tlearn: 0.1264973\ttotal: 17.7s\tremaining: 4.88s\n",
      "784:\tlearn: 0.1262811\ttotal: 17.7s\tremaining: 4.85s\n",
      "785:\tlearn: 0.1260517\ttotal: 17.7s\tremaining: 4.83s\n",
      "786:\tlearn: 0.1259190\ttotal: 17.8s\tremaining: 4.81s\n",
      "787:\tlearn: 0.1257494\ttotal: 17.8s\tremaining: 4.79s\n",
      "788:\tlearn: 0.1256795\ttotal: 17.8s\tremaining: 4.76s\n",
      "789:\tlearn: 0.1254820\ttotal: 17.8s\tremaining: 4.74s\n",
      "790:\tlearn: 0.1252587\ttotal: 17.9s\tremaining: 4.72s\n",
      "791:\tlearn: 0.1249999\ttotal: 17.9s\tremaining: 4.69s\n",
      "792:\tlearn: 0.1248405\ttotal: 17.9s\tremaining: 4.67s\n",
      "793:\tlearn: 0.1245905\ttotal: 17.9s\tremaining: 4.65s\n",
      "794:\tlearn: 0.1244142\ttotal: 17.9s\tremaining: 4.63s\n",
      "795:\tlearn: 0.1242830\ttotal: 18s\tremaining: 4.6s\n",
      "796:\tlearn: 0.1241643\ttotal: 18s\tremaining: 4.58s\n",
      "797:\tlearn: 0.1240551\ttotal: 18s\tremaining: 4.56s\n",
      "798:\tlearn: 0.1238913\ttotal: 18s\tremaining: 4.54s\n",
      "799:\tlearn: 0.1237754\ttotal: 18s\tremaining: 4.51s\n",
      "800:\tlearn: 0.1236944\ttotal: 18.1s\tremaining: 4.49s\n",
      "801:\tlearn: 0.1236278\ttotal: 18.1s\tremaining: 4.47s\n",
      "802:\tlearn: 0.1233572\ttotal: 18.1s\tremaining: 4.44s\n",
      "803:\tlearn: 0.1231191\ttotal: 18.1s\tremaining: 4.42s\n",
      "804:\tlearn: 0.1228824\ttotal: 18.2s\tremaining: 4.4s\n",
      "805:\tlearn: 0.1226667\ttotal: 18.2s\tremaining: 4.38s\n",
      "806:\tlearn: 0.1224914\ttotal: 18.2s\tremaining: 4.35s\n",
      "807:\tlearn: 0.1224187\ttotal: 18.2s\tremaining: 4.33s\n",
      "808:\tlearn: 0.1222198\ttotal: 18.2s\tremaining: 4.31s\n",
      "809:\tlearn: 0.1219931\ttotal: 18.3s\tremaining: 4.29s\n",
      "810:\tlearn: 0.1218527\ttotal: 18.3s\tremaining: 4.26s\n",
      "811:\tlearn: 0.1216892\ttotal: 18.3s\tremaining: 4.24s\n",
      "812:\tlearn: 0.1215569\ttotal: 18.3s\tremaining: 4.22s\n",
      "813:\tlearn: 0.1214005\ttotal: 18.4s\tremaining: 4.19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814:\tlearn: 0.1212849\ttotal: 18.4s\tremaining: 4.17s\n",
      "815:\tlearn: 0.1210354\ttotal: 18.4s\tremaining: 4.15s\n",
      "816:\tlearn: 0.1208435\ttotal: 18.4s\tremaining: 4.13s\n",
      "817:\tlearn: 0.1206141\ttotal: 18.4s\tremaining: 4.1s\n",
      "818:\tlearn: 0.1204583\ttotal: 18.5s\tremaining: 4.08s\n",
      "819:\tlearn: 0.1203888\ttotal: 18.5s\tremaining: 4.06s\n",
      "820:\tlearn: 0.1202878\ttotal: 18.5s\tremaining: 4.03s\n",
      "821:\tlearn: 0.1201462\ttotal: 18.5s\tremaining: 4.01s\n",
      "822:\tlearn: 0.1199414\ttotal: 18.5s\tremaining: 3.99s\n",
      "823:\tlearn: 0.1198505\ttotal: 18.6s\tremaining: 3.96s\n",
      "824:\tlearn: 0.1196721\ttotal: 18.6s\tremaining: 3.94s\n",
      "825:\tlearn: 0.1194521\ttotal: 18.6s\tremaining: 3.92s\n",
      "826:\tlearn: 0.1191849\ttotal: 18.6s\tremaining: 3.9s\n",
      "827:\tlearn: 0.1190275\ttotal: 18.7s\tremaining: 3.88s\n",
      "828:\tlearn: 0.1188004\ttotal: 18.7s\tremaining: 3.85s\n",
      "829:\tlearn: 0.1187186\ttotal: 18.7s\tremaining: 3.83s\n",
      "830:\tlearn: 0.1184930\ttotal: 18.7s\tremaining: 3.81s\n",
      "831:\tlearn: 0.1183618\ttotal: 18.7s\tremaining: 3.78s\n",
      "832:\tlearn: 0.1181713\ttotal: 18.8s\tremaining: 3.76s\n",
      "833:\tlearn: 0.1180270\ttotal: 18.8s\tremaining: 3.74s\n",
      "834:\tlearn: 0.1179387\ttotal: 18.8s\tremaining: 3.72s\n",
      "835:\tlearn: 0.1177712\ttotal: 18.8s\tremaining: 3.69s\n",
      "836:\tlearn: 0.1175306\ttotal: 18.9s\tremaining: 3.67s\n",
      "837:\tlearn: 0.1174059\ttotal: 18.9s\tremaining: 3.65s\n",
      "838:\tlearn: 0.1172307\ttotal: 18.9s\tremaining: 3.63s\n",
      "839:\tlearn: 0.1170322\ttotal: 18.9s\tremaining: 3.6s\n",
      "840:\tlearn: 0.1167028\ttotal: 18.9s\tremaining: 3.58s\n",
      "841:\tlearn: 0.1164470\ttotal: 19s\tremaining: 3.56s\n",
      "842:\tlearn: 0.1161968\ttotal: 19s\tremaining: 3.54s\n",
      "843:\tlearn: 0.1160345\ttotal: 19s\tremaining: 3.51s\n",
      "844:\tlearn: 0.1158851\ttotal: 19s\tremaining: 3.49s\n",
      "845:\tlearn: 0.1157939\ttotal: 19.1s\tremaining: 3.47s\n",
      "846:\tlearn: 0.1155626\ttotal: 19.1s\tremaining: 3.45s\n",
      "847:\tlearn: 0.1154380\ttotal: 19.1s\tremaining: 3.42s\n",
      "848:\tlearn: 0.1153826\ttotal: 19.1s\tremaining: 3.4s\n",
      "849:\tlearn: 0.1152496\ttotal: 19.1s\tremaining: 3.38s\n",
      "850:\tlearn: 0.1150728\ttotal: 19.2s\tremaining: 3.35s\n",
      "851:\tlearn: 0.1149490\ttotal: 19.2s\tremaining: 3.33s\n",
      "852:\tlearn: 0.1148211\ttotal: 19.2s\tremaining: 3.31s\n",
      "853:\tlearn: 0.1147153\ttotal: 19.2s\tremaining: 3.29s\n",
      "854:\tlearn: 0.1146192\ttotal: 19.3s\tremaining: 3.27s\n",
      "855:\tlearn: 0.1145018\ttotal: 19.3s\tremaining: 3.24s\n",
      "856:\tlearn: 0.1143373\ttotal: 19.3s\tremaining: 3.22s\n",
      "857:\tlearn: 0.1141866\ttotal: 19.3s\tremaining: 3.2s\n",
      "858:\tlearn: 0.1140477\ttotal: 19.3s\tremaining: 3.17s\n",
      "859:\tlearn: 0.1139527\ttotal: 19.4s\tremaining: 3.15s\n",
      "860:\tlearn: 0.1137221\ttotal: 19.4s\tremaining: 3.13s\n",
      "861:\tlearn: 0.1135955\ttotal: 19.4s\tremaining: 3.11s\n",
      "862:\tlearn: 0.1134197\ttotal: 19.4s\tremaining: 3.08s\n",
      "863:\tlearn: 0.1131556\ttotal: 19.5s\tremaining: 3.06s\n",
      "864:\tlearn: 0.1129962\ttotal: 19.5s\tremaining: 3.04s\n",
      "865:\tlearn: 0.1128833\ttotal: 19.5s\tremaining: 3.02s\n",
      "866:\tlearn: 0.1127832\ttotal: 19.5s\tremaining: 2.99s\n",
      "867:\tlearn: 0.1126755\ttotal: 19.5s\tremaining: 2.97s\n",
      "868:\tlearn: 0.1123689\ttotal: 19.6s\tremaining: 2.95s\n",
      "869:\tlearn: 0.1121934\ttotal: 19.6s\tremaining: 2.93s\n",
      "870:\tlearn: 0.1120633\ttotal: 19.6s\tremaining: 2.9s\n",
      "871:\tlearn: 0.1119560\ttotal: 19.6s\tremaining: 2.88s\n",
      "872:\tlearn: 0.1118516\ttotal: 19.6s\tremaining: 2.86s\n",
      "873:\tlearn: 0.1117439\ttotal: 19.7s\tremaining: 2.84s\n",
      "874:\tlearn: 0.1114667\ttotal: 19.7s\tremaining: 2.81s\n",
      "875:\tlearn: 0.1113187\ttotal: 19.7s\tremaining: 2.79s\n",
      "876:\tlearn: 0.1112153\ttotal: 19.7s\tremaining: 2.77s\n",
      "877:\tlearn: 0.1110658\ttotal: 19.8s\tremaining: 2.75s\n",
      "878:\tlearn: 0.1109103\ttotal: 19.8s\tremaining: 2.72s\n",
      "879:\tlearn: 0.1106974\ttotal: 19.8s\tremaining: 2.7s\n",
      "880:\tlearn: 0.1105511\ttotal: 19.8s\tremaining: 2.68s\n",
      "881:\tlearn: 0.1103128\ttotal: 19.9s\tremaining: 2.66s\n",
      "882:\tlearn: 0.1101393\ttotal: 19.9s\tremaining: 2.63s\n",
      "883:\tlearn: 0.1099348\ttotal: 19.9s\tremaining: 2.61s\n",
      "884:\tlearn: 0.1098292\ttotal: 19.9s\tremaining: 2.59s\n",
      "885:\tlearn: 0.1096745\ttotal: 19.9s\tremaining: 2.57s\n",
      "886:\tlearn: 0.1094987\ttotal: 20s\tremaining: 2.54s\n",
      "887:\tlearn: 0.1093268\ttotal: 20s\tremaining: 2.52s\n",
      "888:\tlearn: 0.1091317\ttotal: 20s\tremaining: 2.5s\n",
      "889:\tlearn: 0.1090708\ttotal: 20s\tremaining: 2.48s\n",
      "890:\tlearn: 0.1088160\ttotal: 20.1s\tremaining: 2.45s\n",
      "891:\tlearn: 0.1086764\ttotal: 20.1s\tremaining: 2.43s\n",
      "892:\tlearn: 0.1085907\ttotal: 20.1s\tremaining: 2.41s\n",
      "893:\tlearn: 0.1084580\ttotal: 20.1s\tremaining: 2.38s\n",
      "894:\tlearn: 0.1082726\ttotal: 20.1s\tremaining: 2.36s\n",
      "895:\tlearn: 0.1081929\ttotal: 20.2s\tremaining: 2.34s\n",
      "896:\tlearn: 0.1080959\ttotal: 20.2s\tremaining: 2.32s\n",
      "897:\tlearn: 0.1078852\ttotal: 20.2s\tremaining: 2.29s\n",
      "898:\tlearn: 0.1078067\ttotal: 20.2s\tremaining: 2.27s\n",
      "899:\tlearn: 0.1076224\ttotal: 20.3s\tremaining: 2.25s\n",
      "900:\tlearn: 0.1074686\ttotal: 20.3s\tremaining: 2.23s\n",
      "901:\tlearn: 0.1073218\ttotal: 20.3s\tremaining: 2.2s\n",
      "902:\tlearn: 0.1070844\ttotal: 20.3s\tremaining: 2.18s\n",
      "903:\tlearn: 0.1068793\ttotal: 20.3s\tremaining: 2.16s\n",
      "904:\tlearn: 0.1067445\ttotal: 20.4s\tremaining: 2.14s\n",
      "905:\tlearn: 0.1066346\ttotal: 20.4s\tremaining: 2.11s\n",
      "906:\tlearn: 0.1065630\ttotal: 20.4s\tremaining: 2.09s\n",
      "907:\tlearn: 0.1063647\ttotal: 20.4s\tremaining: 2.07s\n",
      "908:\tlearn: 0.1062771\ttotal: 20.4s\tremaining: 2.05s\n",
      "909:\tlearn: 0.1061315\ttotal: 20.5s\tremaining: 2.02s\n",
      "910:\tlearn: 0.1059818\ttotal: 20.5s\tremaining: 2s\n",
      "911:\tlearn: 0.1058195\ttotal: 20.5s\tremaining: 1.98s\n",
      "912:\tlearn: 0.1057092\ttotal: 20.5s\tremaining: 1.96s\n",
      "913:\tlearn: 0.1055772\ttotal: 20.6s\tremaining: 1.93s\n",
      "914:\tlearn: 0.1055100\ttotal: 20.6s\tremaining: 1.91s\n",
      "915:\tlearn: 0.1052994\ttotal: 20.6s\tremaining: 1.89s\n",
      "916:\tlearn: 0.1052095\ttotal: 20.6s\tremaining: 1.86s\n",
      "917:\tlearn: 0.1050347\ttotal: 20.6s\tremaining: 1.84s\n",
      "918:\tlearn: 0.1047819\ttotal: 20.7s\tremaining: 1.82s\n",
      "919:\tlearn: 0.1046082\ttotal: 20.7s\tremaining: 1.8s\n",
      "920:\tlearn: 0.1044527\ttotal: 20.7s\tremaining: 1.78s\n",
      "921:\tlearn: 0.1043223\ttotal: 20.7s\tremaining: 1.75s\n",
      "922:\tlearn: 0.1041440\ttotal: 20.8s\tremaining: 1.73s\n",
      "923:\tlearn: 0.1039173\ttotal: 20.8s\tremaining: 1.71s\n",
      "924:\tlearn: 0.1038321\ttotal: 20.8s\tremaining: 1.69s\n",
      "925:\tlearn: 0.1037918\ttotal: 20.8s\tremaining: 1.66s\n",
      "926:\tlearn: 0.1035720\ttotal: 20.8s\tremaining: 1.64s\n",
      "927:\tlearn: 0.1033997\ttotal: 20.9s\tremaining: 1.62s\n",
      "928:\tlearn: 0.1033285\ttotal: 20.9s\tremaining: 1.6s\n",
      "929:\tlearn: 0.1032459\ttotal: 20.9s\tremaining: 1.57s\n",
      "930:\tlearn: 0.1030465\ttotal: 20.9s\tremaining: 1.55s\n",
      "931:\tlearn: 0.1029124\ttotal: 21s\tremaining: 1.53s\n",
      "932:\tlearn: 0.1027659\ttotal: 21s\tremaining: 1.51s\n",
      "933:\tlearn: 0.1025348\ttotal: 21s\tremaining: 1.48s\n",
      "934:\tlearn: 0.1023895\ttotal: 21s\tremaining: 1.46s\n",
      "935:\tlearn: 0.1023056\ttotal: 21s\tremaining: 1.44s\n",
      "936:\tlearn: 0.1021916\ttotal: 21.1s\tremaining: 1.42s\n",
      "937:\tlearn: 0.1020715\ttotal: 21.1s\tremaining: 1.39s\n",
      "938:\tlearn: 0.1019793\ttotal: 21.1s\tremaining: 1.37s\n",
      "939:\tlearn: 0.1018238\ttotal: 21.1s\tremaining: 1.35s\n",
      "940:\tlearn: 0.1017613\ttotal: 21.2s\tremaining: 1.33s\n",
      "941:\tlearn: 0.1016068\ttotal: 21.2s\tremaining: 1.3s\n",
      "942:\tlearn: 0.1014162\ttotal: 21.2s\tremaining: 1.28s\n",
      "943:\tlearn: 0.1012932\ttotal: 21.2s\tremaining: 1.26s\n",
      "944:\tlearn: 0.1011880\ttotal: 21.2s\tremaining: 1.24s\n",
      "945:\tlearn: 0.1010386\ttotal: 21.3s\tremaining: 1.21s\n",
      "946:\tlearn: 0.1009984\ttotal: 21.3s\tremaining: 1.19s\n",
      "947:\tlearn: 0.1007789\ttotal: 21.3s\tremaining: 1.17s\n",
      "948:\tlearn: 0.1006454\ttotal: 21.3s\tremaining: 1.15s\n",
      "949:\tlearn: 0.1005402\ttotal: 21.4s\tremaining: 1.12s\n",
      "950:\tlearn: 0.1003767\ttotal: 21.4s\tremaining: 1.1s\n",
      "951:\tlearn: 0.1002095\ttotal: 21.4s\tremaining: 1.08s\n",
      "952:\tlearn: 0.1001040\ttotal: 21.4s\tremaining: 1.06s\n",
      "953:\tlearn: 0.0999534\ttotal: 21.4s\tremaining: 1.03s\n",
      "954:\tlearn: 0.0998504\ttotal: 21.5s\tremaining: 1.01s\n",
      "955:\tlearn: 0.0997246\ttotal: 21.5s\tremaining: 989ms\n",
      "956:\tlearn: 0.0995580\ttotal: 21.5s\tremaining: 966ms\n",
      "957:\tlearn: 0.0994039\ttotal: 21.5s\tremaining: 944ms\n",
      "958:\tlearn: 0.0992355\ttotal: 21.6s\tremaining: 921ms\n",
      "959:\tlearn: 0.0990995\ttotal: 21.6s\tremaining: 899ms\n",
      "960:\tlearn: 0.0989749\ttotal: 21.6s\tremaining: 877ms\n",
      "961:\tlearn: 0.0987612\ttotal: 21.6s\tremaining: 854ms\n",
      "962:\tlearn: 0.0986365\ttotal: 21.6s\tremaining: 832ms\n",
      "963:\tlearn: 0.0985106\ttotal: 21.7s\tremaining: 809ms\n",
      "964:\tlearn: 0.0983813\ttotal: 21.7s\tremaining: 787ms\n",
      "965:\tlearn: 0.0982083\ttotal: 21.7s\tremaining: 764ms\n",
      "966:\tlearn: 0.0979885\ttotal: 21.7s\tremaining: 742ms\n",
      "967:\tlearn: 0.0977988\ttotal: 21.8s\tremaining: 720ms\n",
      "968:\tlearn: 0.0976129\ttotal: 21.8s\tremaining: 697ms\n",
      "969:\tlearn: 0.0975192\ttotal: 21.8s\tremaining: 675ms\n",
      "970:\tlearn: 0.0973601\ttotal: 21.8s\tremaining: 652ms\n",
      "971:\tlearn: 0.0973101\ttotal: 21.9s\tremaining: 630ms\n",
      "972:\tlearn: 0.0971565\ttotal: 21.9s\tremaining: 607ms\n",
      "973:\tlearn: 0.0970390\ttotal: 21.9s\tremaining: 585ms\n",
      "974:\tlearn: 0.0970100\ttotal: 21.9s\tremaining: 562ms\n",
      "975:\tlearn: 0.0968894\ttotal: 21.9s\tremaining: 540ms\n",
      "976:\tlearn: 0.0967934\ttotal: 22s\tremaining: 517ms\n",
      "977:\tlearn: 0.0966060\ttotal: 22s\tremaining: 495ms\n",
      "978:\tlearn: 0.0965468\ttotal: 22s\tremaining: 472ms\n",
      "979:\tlearn: 0.0963471\ttotal: 22s\tremaining: 450ms\n",
      "980:\tlearn: 0.0961791\ttotal: 22.1s\tremaining: 427ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981:\tlearn: 0.0961011\ttotal: 22.1s\tremaining: 405ms\n",
      "982:\tlearn: 0.0959597\ttotal: 22.1s\tremaining: 382ms\n",
      "983:\tlearn: 0.0958246\ttotal: 22.1s\tremaining: 360ms\n",
      "984:\tlearn: 0.0957399\ttotal: 22.2s\tremaining: 337ms\n",
      "985:\tlearn: 0.0956420\ttotal: 22.2s\tremaining: 315ms\n",
      "986:\tlearn: 0.0955897\ttotal: 22.2s\tremaining: 292ms\n",
      "987:\tlearn: 0.0954587\ttotal: 22.2s\tremaining: 270ms\n",
      "988:\tlearn: 0.0952728\ttotal: 22.2s\tremaining: 247ms\n",
      "989:\tlearn: 0.0951720\ttotal: 22.3s\tremaining: 225ms\n",
      "990:\tlearn: 0.0950604\ttotal: 22.3s\tremaining: 202ms\n",
      "991:\tlearn: 0.0948306\ttotal: 22.3s\tremaining: 180ms\n",
      "992:\tlearn: 0.0947401\ttotal: 22.3s\tremaining: 157ms\n",
      "993:\tlearn: 0.0946353\ttotal: 22.3s\tremaining: 135ms\n",
      "994:\tlearn: 0.0944649\ttotal: 22.4s\tremaining: 112ms\n",
      "995:\tlearn: 0.0943508\ttotal: 22.4s\tremaining: 89.9ms\n",
      "996:\tlearn: 0.0941627\ttotal: 22.4s\tremaining: 67.5ms\n",
      "997:\tlearn: 0.0940249\ttotal: 22.4s\tremaining: 45ms\n",
      "998:\tlearn: 0.0939881\ttotal: 22.5s\tremaining: 22.5ms\n",
      "999:\tlearn: 0.0939557\ttotal: 22.5s\tremaining: 0us\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=12, objective='binary:logistic', random_state=42,\n",
      "       reg_alpha=0, reg_lambda=3, scale_pos_weight=0.8, seed=None,\n",
      "       silent=False, subsample=1)\n",
      "Before Num features= 15712 Counter({1: 1058, 0: 727})\n",
      "After Num features= 260\n"
     ]
    }
   ],
   "source": [
    "#list_of_model = ['decision_tree_classifier', 'gaussian', 'logistic_regression', 'MLPClassifier', 'RandomForestClassifier',\n",
    "#                 'SVC', 'Catboost', 'XGB_classifier']\n",
    "list_of_model = [ 'Catboost','XGB_classifier']\n",
    "\n",
    "for each_model in list_of_model:\n",
    "    model=get_model(m_type=each_model)\n",
    "    binny_classifier_run(X,y,model,each_model,label_map,img_name,report_name,save_model=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
